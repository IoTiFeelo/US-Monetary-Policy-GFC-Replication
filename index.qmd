---
title: "A Proxy-SVAR Reproduction Model"
author: "Carbonara without Cream"
execute:
  echo: false
bibliography: references.bib
editor: 
  markdown: 
    wrap: 72
---

```{css, echo = FALSE}
.justify {
text-align: justify !important
}
```
::: justify 
**Keywords.** proxy svars, impulse
responses, U.S. mps

# Introduction

I replicate @miranda2020us, Review of Economic Studies. In their paper,
the authors jointly evaluate the effects of financial, monetary and real
variables, in the U.S. and abroad, following a 1% shock of the Federal
Reserve (FED) interest rate. In particular, the authors rely on an
instrumental variable to identify U.S. monetary policy shocks. This is
to avoid implausible restrictions on their variable of interest. My task
will be to understand the model of these two scholars and replicate it
with simplifications given the time scope of the Macroeconometrics
course taught by Dr. [Tomasz
Wo≈∫niak](https://findanexpert.unimelb.edu.au/profile/426516-tomasz-wozniak).
The specific challenge will be writing R codes to disentangle their
framework.

# The Paper

## Global Factor in Risky Asset Prices

[Miranda-Agrippino and
Rey](http://helenerey.eu/Content/_Documents/MirandaAgrippinoRey_REStud_Final.pdf)
in the first part of the paper estimate a global factor to proxy the
movement of world risky asset prices. They do so by collecting 858
prices of different risky assets traded in North America, Latin America,
Europe, Asia Pacific, and Australia, from 1990 to 2012. Their method is
to pick a representative market index (i.e. S&P 500) for each market at
the end of 2012, including all of its components, selecting prices that
allow them to cover at least 80% of cross sectional observations by 1990
and 95% in 1995. They do so to avoid over-representation of each
category. With this global factor, they can explain over 20% of global
risky asset price volatility in their time span. Given the small time
frame and VAR analysis limitations, they estimate a global factor with
commodities from the U.S., Europe, and Japan, spanning back to 1975.
This factor covers 60% of the volatility in this period. The appendix of
the paper provides detailed information on this VAR estimation. To
provide more intuition on this factor, the authors correlate it with
some indexes of implied volatility such as the VIX, outlining its
co-movement with common measures of market variation (in this case a
negative correlation). The global factor will be used later in the
impulse-response section.

```{r}
#| echo: false
#| #| message: false
#| warning: false
#set working directory 
#setwd("/Users/filo/Dropbox/Macrometrics/US-Monetary-Policy-and-the-Global-Financial-Cycle-Replication")
##########################################################################################
  library(readxl)
  library(ggplot2)
  library(rmarkdown)
  library(matrixcalc)
  library(mvtnorm)
  library(parallel)
  library(fredr)
  library(sovereign)
  library(MASS)
  #library(gridExtra)
  library(patchwork)
##########################################################################################
  set.seed(23)

  url <- "http://silviamirandaagrippino.com/s/DFM-Blocks.zip"
  download.file(url, "MAR(2020)")
  unzip("MAR(2020)")
  data <- read_excel("GFC_VARdata+WEB.xlsx", skip=1, .name_repair = "unique_quiet")
  inst <- read_excel("GFC_VARdata+WEB.xlsx", sheet = 2, skip=1, .name_repair = "unique_quiet")
  #date = ts(seq(from = as.Date("1980-01-01"), to = as.Date("2012-12-01"), by = 'month'))
  #instrument$LABEL <- date #ts object is not able to translate dates
  gf <- read_excel("GFC_VARdata+WEB.xlsx", sheet= 4, skip=2, .name_repair = "unique_quiet", na = "blank")
  #monthly data for monthly FedFundsRate
  fed <- (fredr(series_id = "FEDFUNDS", 
                           observation_start = as.Date("1975-01-01"), 
                           frequency = "m",
                           aggregation_method = "average"))
  ############################################################
  ############################################################
  #time series of variables 
  #fed       = ts((fed[,3]), start=c(1980,1), frequency=12) #FED federal funds rate
  instrument = ts((inst$FF4), start=c(1980,1), frequency=12) #FFF4 instrument
  dgs1       = ts((data$DGS1), start=c(1980,1), frequency=12) #1 Year Treasury Rate
  pce        = ts((data$PCEPI), start=c(1980,1), frequency=12) #PCE Deflator; 
  bis        = ts((data$BISREER), start=c(1980,1), frequency=12) #BIS real EER
  globalf    = ts((data$GLOBALF), start=c(1980,1), frequency=12) #Global Factor
  globalra   = ts((data$GLOBALRA), start=c(1980,1), frequency=12) #Global Risk Aversion
  greaexus   = ts((data$GREAEXUS), start=c(1980,1), frequency=12) #Global Real Economic Activity Ex US
  indpro     = ts((data$INDPRO), start=c(1980,1), frequency=12) #industrial production
  glbcredit  = ts((data$GLBCREDIT), start=c(1980,1), frequency=12) #Global Domestic Credit
  glbinflows = ts((data$GLBINFLALL), start=c(1980,1), frequency=12) #Global Inflows All Sectors
  usbdlev    = ts((data$USBDLEV), start=c(1980,1), frequency=12) #Leverage US Brokers and Dealers
  eubdlev    = ts((data$EUBDLEV), start=c(1980,1), frequency=12) #Leverage EU Global Banks
  usbanksl   = ts((data$USBANKSL), start=c(1980,1), frequency=12) #Leverage US Banks
  eubanksl   = ts((data$EUBANKSL), start=c(1980,1), frequency=12) #Leverage EU Banks

  #create the bigy matrix with my data
  y = cbind(instrument,
    pce, 
    dgs1, 
    bis, 
    globalf, 
    globalra, 
    greaexus, 
    glbcredit, 
    indpro,
    glbinflows, 
    usbdlev, 
    eubdlev, 
    usbanksl, 
    eubanksl)
  
    #data in selected window
    y                   <- window(y, start=c(1990,2), end=c(2010,12))
    
  ############################################################
  ############################################################
```

```{r}
#| echo: true 
#| message: false
#| warning: false
#plot of global factors with VIX
  ggplot() + 
    geom_line(data = gf, aes(x = `...1`, y = `GLOBAL FACTOR 1975-2010`, linetype = "solid"), color ="blue", na.rm = TRUE, linewidth=1.2) + 
    geom_line(data = gf, aes(x = `...1`, y = `GLOBAL FACTOR 1990-2012`, linetype = "twodash"), color="blue4", na.rm = TRUE, linewidth=1.2) +
    geom_line(data = data, aes(x = `LABEL`, y = VIX, linetype = "dotted"), color="black", na.rm = TRUE, linewidth=1.2) +
    scale_linetype_manual(values=c("solid", "twodash", "dotted"), name="Global Factors", 
                          labels=c("VIX", "GF 1975-2010", "GF 1990-2012")) +
    guides(linetype = guide_legend(override.aes = list(color = c("black", "blue", "blue4")))) +
    labs(x ="", y="", title= "Global Factor for Risky Asset Prices") + theme(plot.title = element_text(size=20)) +
    theme(legend.text = element_text(size=20),legend.title = element_text(size=12, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
          plot.background = element_rect(fill = "white"), axis.text = element_text(size = 14))

```

## Proxy-VAR Analysis with Rich-Information Bayesian VAR

In this project, I will avoid the computation of the global factor,
because it is out of scope of the Macroeconomerics subject. Instead, I
will concentrate on the Bayesian VAR analysis of Miranda-Agrippino and
Rey. A main reason why the authors studied the monetary effects of U.S.
interest rate changes is that the dollar is the currency of global
banking. A change in FED monetary policy affects banks' borrowing
capacity, the pricing of dollar denominated assets, and cross-border
capital flows. In order to isolate its effects, the two scholars
identify U.S. monetary policy shocks by exploiting 30-min price
revisions around Federal Open Market Committee
([FOMC](https://www.federalreserve.gov/monetarypolicy/fomc.htm))
announcements in the fourth federal funds futures contracts
([FF4](https://www.investopedia.com/terms/f/fed-funds-futures.asp)). The
intuition is that these
[futures](https://www.investopedia.com/terms/f/futures.asp) have an
average maturity of three months, and they can predict revisions of
market expectations about future monetary policy one-quarter in advance.
This assumption holds only if market participants can distinguish
between the systematic component of policy and any observable policy
action. Moreover, with asymmetrical information, the FF4 revisions
contain information about the influence of economic factors relevant to
U.S. monetary policy. Policy announcements provide this information
implicitly.

## The Data

I download the data directly from the website of Miranda-Agrippino. The
two authors study the consequences of a 1% increase in the U.S. monetary
policy considering:

-a domestic VAR with the effects on domestic financial markets and
macroeconomic aggregates in the United States;

-a global VAR with the effects on global asset markets, global domestic
credit and international capital flows;

-a "floaters" VAR to study if a fixed or pegged exchange rate affects
the global contraction.

I will study the global specifications, and I will include the following
variables:

```{r}
#| message: false
#| warning: false
  library(ggplot2)
  library(patchwork)
  ############################################################
  ############################################################  
fed.gdp.plot <-  (ggplot(data=data) + 
    geom_line(aes(x = `LABEL`, y = `DGS1`, linetype = "solid"), na.rm = TRUE, color = "blue") 
    + geom_line(aes(x = `LABEL`, y = `GREAEXUS`, linetype = "dashed"), na.rm = TRUE, color = "black")+
    scale_linetype_manual(values=c("solid", "dashed"), name="", labels=c("Global Real Economic Activity Ex US", "1 Year Treasury Rate"), guide = guide_legend(override.aes = list(color = c("blue", "black")), nrow=2)) +
    guides(linetype = guide_legend(override.aes = list(color = c("black", "blue")), nrow=2)) +
    labs(x ="", y="", title= "Treasury Rate and Global \nReal Activity Index") +
      theme(legend.text = element_text(size=6),legend.title = element_text(size=5, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5, size=11), panel.border = element_blank(), panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
            plot.background = element_rect(fill = "white"), axis.text =element_text(size = 10)))
  ############################################################
  ############################################################
  pce.plot <- (ggplot(data=data) +
     geom_line(aes(x = `LABEL`, y = PCEPI, linetype = "solid"), na.rm = TRUE, color = "blue") +
     scale_linetype_manual(values=c("solid"), name="", labels=c("PCE Deflator"), guide = guide_legend(override.aes = list(color = c("blue")))) +
     guides(linetype = guide_legend(override.aes = list(color = c("blue")))) +
     labs(x ="", y="", title= "Price Deflator") +
       theme(legend.text = element_text(size=10),legend.title = element_text(size=16, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),
             panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
             plot.background = element_rect(fill = "white"), axis.text = element_text(size = 10)))
  
  
  ############################################################
  ############################################################
  leverage.plot <-  (ggplot(data=data) + 
    geom_line(aes(x = `LABEL`, y = EUBDLEV, linetype = "solid"), na.rm = TRUE, color = "blue", linewidth=1.1) + 
    geom_line(aes(x = `LABEL`, y = USBANKSL, linetype = "dashed"), na.rm = TRUE, color = "black", linewidth=1.1) + 
    geom_line(aes(x = `LABEL`, y = EUBANKSL, linetype = "twodash"), na.rm = TRUE, color = "purple", linewidth=1.1) +
    geom_line(aes(x = `LABEL`, y = USBDLEV, linetype = "dotted"), na.rm = TRUE, color = "violet", linewidth=1.1) +
    scale_linetype_manual(values=c("solid", "dashed", "twodash", "dotted"), name="", labels=c("Leverage EU Banks", "Leverage EU Global Banks", "Leverage US Banks", "Leverage US Brokers and Dealers"), guide = guide_legend(override.aes = list(color = c("blue", "black", "purple", "violet")))) +
    guides(linetype = guide_legend(override.aes = list(color = c("black", "blue", "purple", "violet")))) +
    labs(x ="", y="", title= "Leverage") +
      theme(legend.text = element_text(size=7),legend.title = element_text(size=16, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
            plot.background = element_rect(fill = "white"), axis.text = element_text(size = 10)))
  ############################################################
  ############################################################
  mixed.types.plot <-   (ggplot(data=data) + 
     geom_line(aes(x = `LABEL`, y = GLBINFLALL, linetype = "solid"), na.rm = TRUE, color = "blue", linewidth=1.1) + 
     geom_line(aes(x = `LABEL`, y = INDPRO, linetype = "dashed"), na.rm = TRUE, color = "black", linewidth=1.1) + 
     geom_line(aes(x = `LABEL`, y = GLBCREDIT, linetype = "twodash"), na.rm = TRUE, color = "purple", linewidth=1.1) +
       geom_line(aes(x = `LABEL`, y = BISREER, linetype = "dotted"), na.rm = TRUE, color = "violet", linewidth=1.1) +
     scale_linetype_manual(values=c("solid", "dashed", "twodash", "dotted"), name="", labels=c("Industrial Production","Global Inflows All Sectors", "Global Domestic Credit", "BIS real EER"), guide = guide_legend(override.aes = list(color = c("blue", "black", "purple", "violet")))) +
     guides(linetype = guide_legend(override.aes = list(color = c("black", "blue", "purple", "violet")))) +
     labs(x ="", y="", title= "Production, Inflows, Credit, BIS REER") +
       theme(legend.text = element_text(size=8),legend.title = element_text(size=16, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),
             panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
             plot.background = element_rect(fill = "white"), axis.text = element_text(size = 10)))
  
  ############################################################
  ############################################################
  risk.types.plot <-  (ggplot(data=data) + 
    geom_line(aes(x = `LABEL`, y = GLOBALF, linetype = "solid"), na.rm = TRUE, color = "blue") + 
    geom_line(aes(x = `LABEL`, y = GLOBALRA, linetype = "dashed"), na.rm = TRUE, color = "black") +
    scale_linetype_manual(values=c("solid", "dashed"), name="", labels=c("Global Risk Aversion", "Global Factor"), guide = guide_legend(override.aes = list(color = c("black", "blue")), nrow=2)) +
    labs(x ="", y="", title= "Risk Aversion") +
      theme(legend.text = element_text(size=9),legend.title = element_text(size=16, face="bold"),  legend.position = "bottom", plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),panel.background = element_rect(fill = "white"),
            plot.background = element_rect(fill = "white"), axis.text = element_text(size = 10)))
  ############################################################
  ############################################################
  ############################################################
  ############################################################
  
  #grid.arrange(global.credit, global.inflows, leverage.types, production.types, risk.types, nrow = 5)
  library(patchwork)
  combinedplot.1 <- mixed.types.plot / leverage.plot 
    
  combinedplot.2 <- fed.gdp.plot + risk.types.plot + pce.plot
  
  combinedplot.1
  combinedplot.2
```

## Order of Integration of the Variables

I run an augmented Dickey Fuller (ADF) Test to determine the order of
integration of my variables.
All the variables except the instrument fail to reject the null
hypotheses that the variables present a uni-root. In order to provide
more insight on the order of integration I re-run an ADF test with the
first difference of the variables. I expect it to be integrated of order 1
(I(1)). The ADF test of the first-difference data supports these
expectations:

```{r}
#| message: false
#| warning: false
  library(tseries)
  adf <- as.data.frame(matrix(nrow=14,ncol=3,NA))
  rownames(adf) <- colnames(y[1:14])
  colnames(adf) <- c("Dickey-Fuller","Lag-order", "p-value")
  
  for (i in 1:ncol(y)){
    adf_tmp                 <-  adf.test(y[,i])
    adf[i,"Dickey-Fuller"]  <-  round(as.numeric(adf_tmp[1]),3)
    adf[i,"Lag-order"]      <-  as.numeric(adf_tmp[2])
    adf[i,"p-value"]        <-  round(as.numeric(adf_tmp[4]),3)
  }
  
    adf.diff <- as.data.frame(matrix(nrow=14,ncol=3,NA))
  rownames(adf.diff) <- colnames(y[1:14])
  colnames(adf.diff) <- c("Dickey-Fuller diff","Lag-order", "p-value")
  
  for (i in 1: ncol(y)){
    tmp.diff                    <-  adf.test(diff(y[,i]))
    adf.diff[i,"Dickey-Fuller diff"] <-  round(as.numeric(tmp.diff[1]),3)
    adf.diff[i,"Lag-order"]     <-  as.numeric(tmp.diff[2])
    adf.diff[i,"p-value"]       <-  round(as.numeric(tmp.diff[4]),3)
  }
  
  knitr::kable(cbind(adf, adf.diff), index=TRUE)
```

# The Model

## BVAR Framework

From Herwatz, Rohloff & Wang(2022) I define the model as: $$
y_t=B_0B_1y_{t-1}+...+B_0B_py_{t-p}+B_0\varepsilon_t, t=1,..,T $$
$$y_t=A_1y_{t-1}+...+A_py_{t-p}+u_t$$ where $A_j, : \left \{j=1,2,\dots,p\right \}$ where $A(L)=B_0B(L)$ are a K x K coefficient matrices, and L is the lag
operator, and $u_t$ in the first reduced form is serially uncorrelated
with zero mean and positive definite (non-diagonal) covariance matrix
$\Sigma_u.$ The structural shocks $\varepsilon_t$ in the second reduced
form assumed to be mutually uncorrelated and normalised to have unit
variance. $\Xi\left(\varepsilon_t \varepsilon_t' \right)=I_K$.
Structural shocks are mapped to the reduced-form system through a K x K
non-singular matrix $B_0$, such that $B_0^{-1}B_0^{-1'}=\Sigma_u$. For
simplicity, the process is assumed to be causal and
$detA(z)=det(I_k-\sum_{j=1}^{p}A_jz^{j})\neq 0$ for
$\left| z \right|\le 1$. This ensures that the process has a Wold moving
average MA representation. Moreover,

```{=tex}
\begin{align*}
y_t=\mu+\sum_{i=0}^{\infty}\Phi_iu_{t-i}=\mu+\sum_{i=0}^{\infty}\Phi_iB_0\varepsilon_{t-i}=
\mu+\sum_{i=0}^{\infty}\Theta_i\varepsilon_{t-i}.
\end{align*}
```
With: \begin{gather}
\mu=A(1)^{-1}\nu, ::: \Phi_0=I_K, \ \Phi_i=\sum_{j=1}^{i}A_j\Phi_{i-j}, ::: A_j=0 :for: j>p.
\end{gather} The second to last MA representation is of particular
importance because the structural MA coefficients $\Theta_i=\Phi_iB_0$
cannot be recovered without a proper identification. I will briefly
outline the Proxy SVAR approach.

Let $z_t$ be an external instrument to identify the structural shock of
interest $\varepsilon_{kt}, k\:\epsilon \: \left \{1,\dots, K\right \}$.
$z_t$ has to satisfy the *relevant* condition
$\Xi(\varepsilon_{kt}z_t)=\phi \neq 0$ and the *exogeneity* condition
$\Xi(\varepsilon{lt}z_t)=0, \forall l\:\epsilon\left \{1,\dots, K\right \}\setminus\left \{k\right \}$.

From these conditions, it follows that the population covariance between
the instrument and VAR residuals obtain the k-th column if $B_0$,
denoted by $B_{0k}$.

$$
\Xi(u_tz_t) = B_{0,k}\Xi(\varepsilon{kt}z_t)=\phi B_{0,k}
$$

Moreover, let $\Pi$ denotes the $1$x$K$ coefficient vector from the
regression of the instrument on the residual vector $u_t$ gives the
shock $\varepsilon_{kt}$ up to a scale $\phi$.

$\Pi u_t=\Xi(z_tu^{'}_t)\Sigma_{u}^{-1}u_t=\phi B^{'}_{0,k}\left [B_0B_0^{'} \right ]u_t=\phi e^{'}_t\varepsilon_{kt}$

@MollerWolf2021LPVARS, exploiting their result that Local Projections
and VAR impulse response function are equal up to a constant of
proportionality, show that proxy SVARS impulse responses can be computed
putting the instrument in the first row of the data vector $y_t$ in a
SVAR framework. This result follows from the invertibility of $\varepsilon$
and two assumptions: 
-the data $y_t$ is covariance-stationary; 
-the data
$y_t$ is a jointly Gaussian vector time series.
In our Bayesian approach these requirements are met when we define the
distributions of our error terms. I will outline them in the next
section.

## Basic Model
I specify my model to follow a matrix-variate normal distribution
\begin{gather}
Y = XA + E \\
\\ E|X \sim MN_{T \times N}(0_{T \times N},\Sigma,I_T) 
\end{gather} 
Given that the function Y is a linear combination of the error terms E, we can specify 
\begin{gather}
Y|X,A,\sim MN_{T \times N}(XA,\Sigma,I_T)
\end{gather}
Hence, the Likelihood function follows a Matrix-Variate-Normal form: \begin{gather}
L(A,\Sigma|Y,X) \propto det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(Y-XA)'(Y-XA) \right] \right\} \\
\\ \propto det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(A-\hat{A})'X'X(A-\hat{A}) \right] \right\} exp \left\{-\frac{1}{2} tr \left[\Sigma^{-1}(Y-X \hat{A})'(Y-X \hat{A}) \right] \right\} \\
\end{gather}
where from Maximum Likelihood Estimation we have obtained
\begin{gather}
\hat{A} = (X'X)^{-1}X'Y \\
\\ \hat{\Sigma} = \frac{1}{T} (Y-X \hat{A})'(Y-X \hat{A})
\end{gather}
In the basic model, our prior follows a natural-conjugate prior distribution of the same form: \begin{gather}
p(A,\Sigma) = p(A|\Sigma) p(\Sigma) \\
\\ A|\Sigma \sim MN_{K \times N} (\underline{A}, \Sigma , \underline{V}) \\
\\ \Sigma \sim IW_{N}(\underline{S},\underline{\nu})
\end{gather}

With parameters: \begin{gather}
\underline{A} = [0_{N \times 1} \quad I_N \quad 0_{N \times (p-1)N}]' \\ 
\\ Var[vec(A)] = \Sigma \otimes  \underline{V} \\
\\ \underline{V} = diag([\kappa_2 \quad \kappa_1 (p^{-2} \otimes I_N)]) \\
\\ p = [1,2,...p]
\end{gather}
The parameter $\kappa_2$ and $kappa_1$ specify respectively the prior of the overall shrinkage level for the constant term and for the autoregressive slopes. I specify $\kappa_2=1$ and $\kappa_1=0.02$ based on the fact that you should shrink the constant term much less than the autoregressive parameters.
Furthermore, the full conditional posterior is: 
\begin{gather}
p(A,\Sigma|Y,X) = p(A|Y,X,\Sigma)p(\Sigma|Y,X) \\
\\ p(A|Y,X,\Sigma) = MN_{K \times N}(\bar{A}, \Sigma, \bar{V}) \\ 
\\ p(\Sigma | Y, X) = IW_N(\bar{S},\bar{\nu})
\end{gather}

We can derive the full conditional posterior: \begin{gather}
P(A,\Sigma|Y,X) \propto L(A,\Sigma|Y,X)p(A,\Sigma) \\
\\ \propto L(A,\Sigma|Y,X)p(A|\Sigma)p(\Sigma) \\
\\ det(\Sigma)^{-\frac{T}{2}} \times exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(A-\hat{A})' X'X (A-\hat{A})\right] \right\} \\
\\ \times exp\left\{-\frac{1}{2}tr \left[ \Sigma^{-1}(Y-X\hat{A})'(Y-X\hat{A}) \right] \right\} \\
\\ \times det(\Sigma)^{-\frac{N+K+\underline{\nu}+1}{2}} \\
\\ \times exp\left\{-\frac{1}{2}tr \left[ \Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A}) \right] \right\} \\ 
\\ \times exp \left\{ -\frac{1}{2} tr \left[ \Sigma^{-1} \underline{S} \right] \right\}
\end{gather}

After some calculations:
```{=tex}
\begin{gather}\\
p(A,\Sigma|Y,X) \propto \\
\\ det{(\Sigma)}^{-\frac{T+N+K+ \underline{\nu}
+1}{2}} \times exp\left\{ -\frac{1}{2} tr \left[ \Sigma^{-1} \left[ (A-\bar{A})^{'} \bar{V}^{-1} (A-\bar{A})+\underline{S} +Y^{'}Y + \underline{A}^{'} \underline{V}^{-1}\underline{A} -\bar{A}^{'} \bar{V}^{-1}\bar{A}\right]\right]\right\}
\end{gather}
```
where the full conditional posterior has the same natural-conjugate form of our prior:
```{=tex}
\begin{gather}
p(A,\Sigma|Y,X) = p(A|Y,X,\Sigma)p(\Sigma|Y,X) \\
\\ p(A|Y,X,\Sigma) = MN_{K \times N}(\bar{A}, \Sigma, \bar{V}) \\
\\ p(\Sigma | Y, X) = IW_N(\bar{S},\bar{\nu})\end{gather}
```
with posterior parameters:
```{=tex}
\begin{gather}
\bar{V} = (X^{'}X+ \underline{V}^{-1})^{-1} \\ 
\\ \bar{A} = \bar{V}(X^{'}Y+\underline{V}^{-1} \underline{A}) \\ 
\\ \bar{\nu} = T + \underline{\nu} \\ 
\\ \bar{S} = \underline{S} + Y^{'}Y +  \underline{A}^{'}\underline{V}^{-1}\underline{A} - \bar{A}^{'}\bar{V}^{-1}\bar{A}
\end{gather}
```
In order to compute our posterior parameters in R, we first specify values for our priors, then we calculate the posteriors and draw $A$ and $\Sigma$ respectively from a Matrix-Variate-normal and Inverse Wishart distributions. 

```{r}
#| echo: true 
#| message: false
#| warning: false
  # setup function for my analysis
  basic.model <- function(bigy, p, S, start, end){
  ############################################################
  N       = ncol(bigy)
  K       = 1+N*p
  ############################################################
  Y       = bigy[(p+1):nrow(bigy),]
  X       = matrix(1,nrow(Y),1)
  for (i in 1:p){
    X     = cbind(X,bigy[(p+1):nrow(bigy)-i,])
  }
  
  A.prior     = matrix(0,K,N)
  A.prior[2:(N+1),] <- diag(c(0,rep(1,N-1))) #0 for the instrument (stationary variable)
  V.prior     = (diag(c(1,0.02*((1:p)^(-2))%x%rep(1,N)))) #1 is kappa.2, 0.02 is kappa.1
  S.prior     = diag(N)
  nu.prior    = N+1
  
  # normal-inverse Wishart posterior parameters
  ############################################################
  V.bar.inv   = t(X)%*%X + diag(1/diag(V.prior)) #X'X+diag(V^-1)
  V.bar       = solve(V.bar.inv) #inv(X'X+diag(V^-1))
  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior) #V.bar(X'X+diag((V.prior)^-1(A.prior)))
  nu.bar      = nrow(Y) + nu.prior 
  S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
  #S.prior+Y'Y+(A.prior)'*diag(diag((V.prior)^-1))*A.prior-A.bar'*(X'X+diag(V^-1))*A.bar
  S.bar.inv   = solve(S.bar)
  
  # posterior draws
  ############################################################
  Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
  Sigma.posterior   = apply(Sigma.posterior,3,solve)
  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) #3 dimensional, S repetitions of rnorm
  B.posterior       = array(NA,c(N,N,S))
  L                 = t(chol(V.bar))
  for (s in 1:S){
    cholSigma.s     = chol(Sigma.posterior[,,s])
    B.posterior[,,s]= t(cholSigma.s)
    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%cholSigma.s
}
  #return the parameters of interest
  results = list("B" = B.posterior, "A" = A.posterior )
  return(results)
  }
```

```{r}
#| echo: false
#| #| message: false
#| warning: false
  #run the function with my data
  basic.results <- basic.model(y, 12, 100, c(1990,2), c(2010,12))

```

##Extended Model

In the extended model, I set hyperprior parameters for the autoregressive parameter $\kappa_A$ to follow an Inverse Gamma 2 distribution $IG2(\underline{S}_{\kappa},\underline{\nu}_{\kappa})$ and $\kappa_{\Sigma}$ hyperprior parameter for the variance-covariance matrix to follow a Gamma Distribution $G(\underline{S}_{\Sigma},\underline{a}_{\Sigma})$.
I will define the full conditional posterior of the hyperparameter $\kappa_A$ first.

\begin{gather}
p(\kappa_a | A,\Sigma, Y,X) \propto L(Y|X,A,\Sigma) \times p(\kappa_a) \times p(A|\Sigma,\kappa_a) \times p(\Sigma|\kappa_a) \\ 
\\ \propto p(\kappa_a) \times p(A|\Sigma,\kappa_a) \\ 
\\ \propto (\kappa_a)^{-\frac{\underline{\nu_a}+2}{2}} 
exp\left\{ -\frac{1}{2} \frac{\underline{S_a}}{\kappa_a} \right\}  \times exp\left\{-\frac{1}{2}tr\left[\Sigma^{-1}(A-\underline{A_{\kappa}})^{'} \frac{1}{\kappa}(\underline{V_{\kappa}})^{-1} (A-\underline{A})\right]\right\} \times det(\kappa_a \underline{V})^{-\frac{N}{2}} \\ 
\\ \propto (\kappa_a)^{-\frac{\underline{\nu_a}_{\kappa_a}+2+NK}{2}} exp \left\{-\frac{1}{2} \frac{1}{\kappa_a} \left[\underline{S_a}_{\kappa_a} + tr \left[\Sigma^{-1}(A-\underline{A})^{'}\underline{V}^{-1}(A-\underline{A}) \right]\right] \right\}
\end{gather}

where we can recognise the kernel of an Inverse Gamma 2 Distribution with

\begin{gather}
\bar{S}_a = \underline{S}_a+tr \left[ \Sigma^{-1} (A-\underline{A})^{'} \underline{V}^{-1} (A-\underline{A})\right] \\
\\ \bar{\nu}_a = \underline{\nu}_a+NK
\end{gather}

In addition, I derive similarly the full conditional posterior of the hyperparameter $\kappa_{\Sigma}$.
\begin{gather}
p(\kappa_{\Sigma} | A,\Sigma, Y,X) \propto
p(\kappa_{\Sigma} | A,\Sigma, Y,X) \propto L(Y|X,A,\Sigma) \times p(\kappa_{\Sigma}) \times p(A|\Sigma,\kappa_a) \times p(\Sigma|\kappa_{\Sigma}) \times p(\kappa_a) \\ 
\\ \propto p(\kappa_{\Sigma}) \times p(\Sigma|\kappa_{\Sigma}) \\ 
\\ \propto (\kappa_{\Sigma})^{-\frac{\underline{\nu}N}{2}} 
exp\left[{ -\frac{1}{2} \frac{\kappa_{\Sigma}}{tr\left [\Sigma^{-1}\underline{s}_{\Sigma} \right ]^{-1}}} \right\}  \times (\kappa_{\Sigma})^{\underline{a}_{\Sigma}-1}exp\left [{-\frac{\kappa_{\Sigma}}{\underline{s}_{\Sigma}}}  \right ] \\
\\ \propto (\kappa_{\Sigma})^\frac{{}{N\underline{\nu}+2\underline{a}_{\Sigma}-2}}{2}exp\left [{-\frac{\kappa_{\Sigma}}{\left [2tr\left[\Sigma^{-1}\underline{s}_{\Sigma} \right ]^{-1}+\left[\underline{s}_{\Sigma} \right ]^{-1}\right ]^{-1}}}  \right ] \\
\end{gather}
where we can recognise the kernel of an Gamma Distribution with
\begin{gather}
\bar{S}_{\Sigma} = {\left [2\left[tr\Sigma^{-1}\underline{s}_{\Sigma} \right ]^{-1}+\left[\underline{s}_{\Sigma} \right ]^{-1}\right ]^{-1}} \\
\\ \bar{a}_{\Sigma} = \frac{N\underline{\nu}}{2}+\underline{a}_{\Sigma}
\end{gather}


Therefore, our new full conditional posterior distribution will be as following:
The full conditional posterior of $(A,\Sigma)$ is: 
\begin{gather}
p(A,\Sigma|X,Y,\kappa_a,\kappa_{\Sigma}) \propto L(A,\Sigma|Y,X) \times p(A|\Sigma,\kappa_a) \times p(\Sigma|\kappa_{\Sigma}) \\
\\ \propto det(\Sigma)^{-\frac{K}{2}} exp \left\{-\frac{1}{2}tr \left[ \Sigma^{-1}(Y-XA)^{'}(Y-XA)\right] \right\} \\
\\ \times exp \left\{ -\frac{1}{2} tr \left[ \Sigma^{-1}(A-\underline{A})^{'}(\kappa_a \underline{V})^{-1}(A-\underline{A}) \right] \right\} \\
\\ \times det(\Sigma)^{\frac{\underline{\nu}+N+1}{2}} exp\left\{-\frac{1}{2} tr \left[\Sigma^{-1}\kappa_{\Sigma} \right] \right\}
\end{gather}

We recognize kernel of matrix-normal inverse Wishart distribution, with parameters as follows: 
\begin{gather}
\bar{V} = (X'X+(\kappa_a \underline{V}))^{-1} \\ 
\\ \bar{A} = \bar{V}(X'Y+(\kappa_a \underline{V}^{-1}\underline{A})) \\ \\ \bar{S} = I_N\kappa_{\Sigma}+Y'Y+\underline{A}^{'}(\kappa_a \underline{V})^{-1}\underline{A} - \bar{A}^{'} \bar{V}^{-1}\bar{A} \\ 
\\ \bar{\nu} = T + \underline{\nu}
\end{gather}

## Gibbs Sampler

In order to reach our analytical solutions we use a Monte Carlo Markov Chain (MCMC) method, namely the Gibbs Sampler procedure. We generate random draws from the joint posterior distribution and we update them at each iteration to compute our posterior distribution parameters. In our case we exploit the following procedure:
Initialize $\kappa_a$ and $\kappa_{\Sigma}$ at $\kappa_a^{(0)}$ and $\kappa^{(0)}_{\Sigma}$

At each iteration s: 

1. Draw $(A,\Sigma)^{(s)} \sim p(A,\Sigma| X,Y,\kappa_a^{(s-1), \kappa_{\Sigma}^{(s-1)})$
2. Draw $\kappa_a^{(s)} \sim p(\kappa_a|Y,X,A,\Sigma)$
3. Draw $\kappa_{\Sigma}^{(s)} \sim p(\kappa_{\Sigma}|Y,X,A,\Sigma)$

Repeat steps 1 and 2 for $(S_1 + S_2)$ times.
Discard the first $S_1$ repetitions.
Return the output as $\left \{ A^{(s)}, \Sigma^{(s)} \right \}^{S2}_{s=S1+1}$.


```{r}
#| echo: true 
#| message: false
#| warning: false
  extended.model <- function(bigy, p, S1, S2){
  ############################################################
  
  Y       = bigy[(p+1):nrow(bigy),]
  X       = matrix(1,nrow(Y),1)
  for (i in 1:p){
    X     = cbind(X,bigy[(p+1):nrow(bigy)-i,])
  }
  
  N       = ncol(bigy)
  K       = 1+N*p
  S=S1+S2 #sum of replications
  # set the priors
  A.prior     = matrix(0,K,N)
  A.prior[2:(N+1),] <- diag(c(0,rep(1,N-1)))
  V.prior         = (diag(c(10,1*((1:p)^(-2))%x%rep(1,N)))) #10 is kappa.2, 1 is kappa.1
  nu.prior        = N+1
  #kappa.a priors
  nu.prior.a      = N + 1        #ig2
  s.a.prior       = 0.01
  s.sigma.prior   = rep(1,N)     #ig2
  #kappa.sigma priors
  s.a.prior       = 0.01        #rgamma
  a.sigma.prior   = 1           #rgamma
  
  A.posterior         = array(rnorm(prod(c(K,N,S))), c(K, N, S))
  B.posterior         = array(NA,c(N,N,S))
  Sigma.post          = array(NA,c(N,N,S))
  k.sigma             = matrix(NA, S, 1)
  k.a                 = matrix(NA, S, 1)
  k.sigma[1] <- 1
  k.a[1]     <- 1
  
  for (s in 1:S) {
    # normal-inverse Wishart, IG2, and Gamma posterior parameters
    ############################################################
    V.bar.inv   = t(X)%*%X + solve(k.a[s]*V.prior)
    V.bar       = solve(V.bar.inv)
    A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(k.a[s]*V.prior))%*%A.prior)
    nu.bar      = nrow(Y) + nu.prior
    nu.bar.a    = nu.prior.a + N*K
    S.bar       = k.sigma[s]*diag(N) + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(k.a[s]*V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv   = solve(S.bar)
    a.sigma.bar = (N*nu.prior)/2+a.sigma.prior
    # posterior draws
    ############################################################
    Sigma.posterior.inv = rWishart(1, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior     = apply(Sigma.posterior.inv,3,solve)
    Sigma.posterior     = matrix(Sigma.posterior, N, N)
    L                   = t(chol(V.bar))
    cholSigma.s       = chol(Sigma.posterior)
    A.posterior[,,s]  = A.bar + L%*%A.posterior[,,s]%*%cholSigma.s
    
    s.a.bar     <- s.a.prior + sum(diag( Sigma.posterior.inv[,,1] %*% t(A.posterior[,,s]-A.prior)%*% diag(1/diag(V.prior)) %*% (A.posterior[,,s]-A.prior)))
    s.sigma.bar   <- (2*(sum(diag(Sigma.posterior.inv[,,1]))^-1)+((s.sigma.prior)^-1))^-1
    if (s <= S){
      #draw k.a from IG2
      k.a[s+1]      <- s.a.bar / rchisq(1, df=nu.bar.a)
      #draw k.sigma from gamma distribution
      k.sigma[s+1]  <- rgamma(1, shape = a.sigma.bar, scale = s.sigma.bar)
    }
    
    B.posterior[,,s]  = t(chol(Sigma.posterior.inv[,,]))
    Sigma.post[,,s]   = Sigma.posterior.inv
  }
  #return the parameters of interest
  results = list("B" = B.posterior[,,S1+1:S2], 
                 "A" = A.posterior[,,S1+1:S2], 
                 "Sigma" = Sigma.post[,,S1+1:S2], 
                 "k.a" = k.a[S1+1:S2], 
                 "k.sigma" = k.sigma[S1+1:S2], 
                 "B.convergence" = B.posterior[,,1:S], 
                 "A.convergence" = A.posterior[,,1:S], 
                 "Sigma.convergence" = Sigma.post[,,1:S], 
                 "k.a.convergence" = k.a[1:S], 
                 "k.sigma.convergence" = k.sigma[1:S])
  return(results)
  }

```

```{r}
#| echo: false
#| #| message: false
#| warning: false
  extended.result     <- extended.model(y, 12, 100, 100) #data, lag, S1 burn in, S2 repetitions to keep
```

## Artificial Data

I generate two random walks $y1$ and $y2$ with 1000 observations each simulated from a bivariate Gaussian random walk process. I plot the raw series and the first difference below:
```{r}
#| echo: true 
#| message: false
#| warning: false
  #artificial data with 1000 observations from a bi-variate Gaussian random walk
  #VAR model with N=2, p=1, and a constant term
  # simulate 1000 samples from the bivariate Gaussian random walk process with cumsum(rnorm())
  y1 <- ts(cumsum(rnorm(1000, 0, sd=1)))
  y2 <- ts(cumsum(rnorm(1000, 0, sd=1)))
  y.art <- cbind(y1,y2)
  
  par(mfrow=c(1,2),mar=c(2,2,2,2))
  plot(y.art, 1:1000, type = "l", main = "Artificial data", ylab="", xlab="")
  plot(diff(y.art), 1:1000, type = "l", main = "Artificial data first difference", ylab="", xlab="")
```
  
Then, I use my two functions from the basic and extended model to simulate the posterior of the intercept term. I show in the plots that for 10 thousand draws I get an intercept close to zero for the $A_{1,1}$ and $A_{1,2}$ values, and an identity matrix for the $B_{1,1}$ and $B_{2,2}$ values.
```{r}
#| echo: true 
#| message: false
#| warning: false
  basic.artificial <- basic.model(y.art, 1, 10000, c(), c())
  extended.artificial <- extended.model(y.art, 1, 1000, 9000)
  B.basic    <- basic.artificial$B
  A.basic    <- basic.artificial$A
  B.extended <- extended.artificial$B.convergence
  A.extended <-extended.artificial$A.convergence
  
  par(mfrow=c(4,2),mar=c(2,2,3,2))
  plot(1:10000, B.basic[1,1,], type = "l", main = expression(paste("basic " , B[1,1])), lwd=0.2, ylab="", xlab="", col="blue1")
    plot(1:10000, B.basic[2,2,], type = "l", main = expression(paste("basic " , B[2,2])), lwd=0.2, ylab="", xlab="", col="blue1")
  plot(1:10000, A.basic[1,1,], type = "l", main = expression(paste("basic " , A[1,1])), lwd=0.2, ylab="", xlab="", col="blue3")
  plot(1:10000, A.basic[1,2,], type = "l", main = expression(paste("basic " , A[1,2])), lwd=0.2, ylab="", xlab="", col="blue3")
  plot(1:10000, B.extended[1,1,], type = "l", main = expression(paste("extended " , B[1,1])), lwd=0.2, ylab="", xlab="", col="blue2")
  plot(1:10000, B.extended[2,2,], type = "l", main = expression(paste("extended " , B[2,2])), lwd=0.2, ylab="", xlab="", col="blue2")
  plot(1:10000, A.extended[1,1,], type = "l", main = expression(paste("extended " , A[1,1])), lwd=0.2, ylab="", xlab="", col="blue4")
  plot(1:10000, A.extended[1,2,], type = "l", main = expression(paste("extended " , A[1,2])), lwd=0.2, ylab="", xlab="", col="blue4")
  
```
Moreover, I also plot the histograms of the values $\kappa_a$ and $\kappa_{\Sigma}$ outlining their mean value. I also add a vertical line to define the mean parameter for all the draws. The initial values for both parameters was set equal to one.
```{r}
#| echo: true 
#| message: false
#| warning: false
par(mfrow=c(1,2),mar=c(2,2,2,2))
hist(extended.artificial$k.a.convergence, breaks="Freedman-Diaconis", main = expression(paste("Slope Hyperparameter ", kappa[a])))
abline(v = mean(extended.artificial$k.a.convergence), col='blue3', lwd = 3)
hist(extended.artificial$k.sigma.convergence, breaks="Freedman-Diaconis",main = expression(paste("Covariance Hyperparameter ", kappa[Sigma])))
abline(v = mean(extended.artificial$k.sigma.convergence), col='red', lwd = 3)
```
# References
:::

[
  {
    "objectID": "index.html#global-factor-in-risky-asset-prices",
    "href": "index.html#global-factor-in-risky-asset-prices",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Global Factor in Risky Asset Prices",
    "text": "Global Factor in Risky Asset Prices\nMiranda-Agrippino and Rey in the first part of the paper estimate a global factor to proxy the movement of world risky asset prices. They do so by collecting 858 prices of different risky assets traded in North America, Latin America, Europe, Asia Pacific, and Australia, from 1990 to 2012. Their method is to pick a representative market index (i.e. S&P 500) for each market at the end of 2012, including all of its components, selecting prices that allow them to cover at least 80% of cross sectional observations by 1990 and 95% in 1995. They do so to avoid over-representation of each category. They use first difference log-priced series. With this global factor, they can explain over 20% of global risky asset price volatility in their time span. Given the small time frame and VAR analysis limitations, they estimate a global factor with commodities from the U.S., Europe, and Japan, spanning back to 1975. This factor covers 60% of the volatility in this period. The appendix of the paper provides detailed information on this VAR estimation. To provide more intuition on this factor, the authors correlate it with some indexes of implied volatility such as the VIX, outlining its co-movement with common measures of market variation (in this case a negative correlation). The global factor will be used later in the impulse-response section.\n\n\n\n\n\nGlobal Factors Plot\nggplot() + \n  geom_line(data = gf, aes(x = `...1`, y = `GLOBAL FACTOR 1975-2010`, linetype = \"GF 1975-2010\"), color =\"blue\", na.rm = TRUE, linewidth=1.2) + \n  geom_line(data = gf, aes(x = `...1`, y = `GLOBAL FACTOR 1990-2012`, linetype = \"GF 1990-2012\"), color=\"purple\", na.rm = TRUE, linewidth=1.2) +\n  geom_line(data = data, aes(x = `LABEL`, y = VIX, linetype = \"VIX\"), color=\"black\", na.rm = TRUE, linewidth=1.2) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\"), \n                        labels = c(\"VIX\", \"GF 1975-2010\", \"GF 1990-2012\"),\n                        guide = guide_legend(override.aes = list(color = c(\"black\", \"blue\", \"purple\")))) +\n  labs(x = \"\", y = \"\", title = \"Global Factor for Risky Asset Prices\") +\n  theme(plot.title = element_text(size = 20)) +\n  theme(legend.text = element_text(size = 20), legend.title = element_text(size = 0), \n        legend.position = \"bottom\", plot.title = element_text(hjust = 0.5), \n        panel.border = element_blank(), panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\"),\n        panel.background = element_rect(fill = \"white\"), plot.background = element_rect(fill = \"white\"), \n        axis.text = element_text(size = 14))"
  },
  {
    "objectID": "index.html#proxy-var-analysis-with-rich-information-bayesian-var",
    "href": "index.html#proxy-var-analysis-with-rich-information-bayesian-var",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Proxy-VAR Analysis with Rich-Information Bayesian VAR",
    "text": "Proxy-VAR Analysis with Rich-Information Bayesian VAR\nIn this project, we will avoid the computation of the global factor, because it is out of scope of the Macroeconomerics subject. Instead, we will concentrate on the Bayesian VAR analysis of Miranda-Agrippino and Rey. A main reason why the authors studied the monetary effects of U.S. interest rate changes is that the dollar is the currency of global banking. A change in FED monetary policy affects banks’ borrowing capacity, the pricing of dollar denominated assets, and cross-border capital flows. In order to isolate its effects, the two scholars identify U.S. monetary policy shocks by exploiting 30-min price revisions around Federal Open Market Committee (FOMC) announcements in the fourth federal funds futures contracts (FF4). The intuition is that these futures have an average maturity of three months, and they can predict revisions of market expectations about future monetary policy one-quarter in advance. This assumption holds only if market participants can distinguish between the systematic component of policy and any observable policy action. Moreover, with asymmetrical information, the FF4 revisions contain information about the influence of economic factors relevant to U.S. monetary policy. Policy announcements provide this information implicitly."
  },
  {
    "objectID": "index.html#the-data",
    "href": "index.html#the-data",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "The Data",
    "text": "The Data\nI download the data directly from the website of Miranda-Agrippino. The two authors study the consequences of a 1% increase in the U.S. monetary policy considering:\n-a domestic VAR with the effects on domestic financial markets and macroeconomic aggregates in the United States;\n-a global VAR with the effects on global asset markets, global domestic credit and international capital flows;\n-a “floaters” VAR to study if a fixed or pegged exchange rate affects the global contraction.\nI will study the global specifications, and I will include the following variables:"
  },
  {
    "objectID": "index.html#bvar-framework",
    "href": "index.html#bvar-framework",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "BVAR Framework",
    "text": "BVAR Framework\nFrom Herwartz (2021) we define the model as: \\[\ny_t=B_0B_1y_{t-1}+...+B_0B_py_{t-p}+B_0\\varepsilon_t, t=1,..,T \\] \\[y_t=A_1y_{t-1}+...+A_py_{t-p}+u_t\\] where \\(A_j, : \\left \\{j=1,2,\\dots,p\\right \\}\\) where \\(A(L)=B_0B(L)\\) are a K x K coefficient matrices, and L is the lag operator, and \\(u_t\\) in the first reduced form is serially uncorrelated with zero mean and positive definite (non-diagonal) covariance matrix \\(\\Sigma_u.\\) The structural shocks \\(\\varepsilon_t\\) in the second reduced form are assumed to be mutually uncorrelated and normalised to have unit variance. \\(\\Xi\\left(\\varepsilon_t \\varepsilon_t' \\right)=I_K\\). Structural shocks are mapped to the reduced-form system through a K x K non-singular matrix \\(B_0\\), such that \\(B_0^{-1}B_0^{-1'}=\\Sigma_u\\). For simplicity, the process is assumed to be causal and \\(detA(z)=det(I_k-\\sum_{j=1}^{p}A_jz^{j})\\neq 0\\) for \\(\\left| z \\right|\\le 1\\). This ensures that the process has a Wold moving average MA representation. Moreover,\n\\[\\begin{align*}\ny_t=\\mu+\\sum_{i=0}^{\\infty}\\Phi_iu_{t-i}=\\mu+\\sum_{i=0}^{\\infty}\\Phi_iB_0\\varepsilon_{t-i}=\n\\mu+\\sum_{i=0}^{\\infty}\\Theta_i\\varepsilon_{t-i}.\n\\end{align*}\\]\nWith: \\[\\begin{gather}\n\\mu=A(1)^{-1}\\nu, ::: \\Phi_0=I_K, \\ \\Phi_i=\\sum_{j=1}^{i}A_j\\Phi_{i-j}, ::: A_j=0 :for: j>p.\n\\end{gather}\\] The second to last MA representation is of particular importance because the structural MA coefficients \\(\\Theta_i=\\Phi_iB_0\\) cannot be recovered without a proper identification. We will briefly outline the Proxy SVAR approach.\nLet \\(z_t\\) be an external instrument to identify the structural shock of interest \\(\\varepsilon_{kt}, k\\:\\epsilon \\: \\left \\{1,\\dots, K\\right \\}\\). \\(z_t\\) has to satisfy the relevant condition \\(\\Xi(\\varepsilon_{kt}z_t)=\\phi \\neq 0\\) and the exogeneity condition \\(\\Xi(\\varepsilon{lt}z_t)=0, \\forall l\\:\\epsilon\\left \\{1,\\dots, K\\right \\}\\setminus\\left \\{k\\right \\}\\).\nFrom these conditions, it follows that the population covariance between the instrument and VAR residuals obtain the k-th column if \\(B_0\\), denoted by \\(B_{0k}\\). \\end{gather} The second to last MA representation is of particular importance because the structural MA coefficients \\(\\Theta_i=\\Phi_iB_0\\) cannot be recovered without a proper identification. We will briefly outline the Proxy SVAR approach. Let \\(z_t\\) be an external instrument to identify the structural shock of interest \\(\\varepsilon_{kt}, k\\:\\epsilon \\: \\left \\{1,\\dots, K\\right \\}\\). \\(z_t\\) has to satisfy the relevant condition \\(\\Xi(\\varepsilon_{kt}z_t)=\\phi \\neq 0\\) and the exogeneity condition \\(\\Xi(\\varepsilon{lt}z_t)=0, \\forall l\\:\\epsilon\\left \\{1,\\dots, K\\right \\}\\setminus\\left \\{k\\right \\}\\). From these conditions, it follows that the population covariance between the instrument and VAR residuals obtains the k-th column of \\(B_0\\), denoted by \\(B_{0k}\\).\n\\[\n\\Xi(u_tz_t) = B_{0,k} \\\\\n\\Xi(\\varepsilon{kt}z_t)=\\phi B_{0,k}\n\\] Moreover, let \\(\\Pi\\) denotes the \\(1\\)x\\(K\\) coefficient vector from the regression of the instrument on the residual vector \\(u_t\\) gives the shock \\(\\varepsilon_{kt}\\) up to a scale \\(\\phi\\). \\(\\Pi u_t=\\Xi(z_tu^{'}_t)\\Sigma_{u}^{-1}u_t=\\phi B^{'}_{0,k}\\left [B_0B_0^{'} \\right ]u_t=\\phi e^{'}_t\\varepsilon_{kt}\\) Plagborg-Moller (2021), exploiting their result that Local Projections and VAR impulse response function are equal up to a constant of proportionality, show that proxy SVARS impulse responses can be computed putting the instrument in the first row of the data vector \\(y_t\\) in a SVAR framework. This result follows from the invertibility of \\(\\varepsilon\\) and two assumptions: -the data \\(y_t\\) is covariance-stationary; -the data \\(y_t\\) is a jointly Gaussian vector time series.\nIn our Bayesian approach these requirements are met when we define the distributions of our error terms. We will outline them in the next section."
  },
  {
    "objectID": "index.html#basic-model",
    "href": "index.html#basic-model",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Basic Model",
    "text": "Basic Model\nWe specify our model to follow a matrix-variate normal distribution \\[\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim MN_{T \\times N}(0_{T \\times N},\\Sigma,I_T)\n\\end{gather}\\] Given that the function Y is a linear combination of the error terms E, we can specify \\[\\begin{gather}\nY|X,A,\\sim MN_{T \\times N}(XA,\\Sigma,I_T)\n\\end{gather}\\] Hence, the Likelihood function follows a Matrix-Variate-Normal form: \\[\\begin{gather}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\} \\\\\n\\\\ \\propto det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\} exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\} \\\\\n\\end{gather}\\] where from Maximum Likelihood Estimation we have obtained \\[\\begin{gather}\n\\hat{A} = (X'X)^{-1}X'Y \\\\\n\\\\ \\hat{\\Sigma} = \\frac{1}{T} (Y-X \\hat{A})'(Y-X \\hat{A})\n\\end{gather}\\] In the basic model, our prior follows a natural-conjugate prior distribution of the same form: \\[\\begin{gather}\np(A,\\Sigma) = p(A|\\Sigma) p(\\Sigma) \\\\\n\\\\ A|\\Sigma \\sim MN_{K \\times N} (\\underline{A}, \\Sigma , \\underline{V}) \\\\\n\\\\ \\Sigma \\sim IW_{N}(\\underline{S},\\underline{\\nu})\n\\end{gather}\\]\nWith parameters: \\[\\begin{gather}\n\\underline{A} = [0_{N \\times 1} \\quad I_N \\quad 0_{N \\times (p-1)N}]' \\\\\n\\\\ Var[vec(A)] = \\Sigma \\otimes  \\underline{V} \\\\\n\\\\ \\underline{V} = diag([\\kappa_2 \\quad \\kappa_1 (p^{-2} \\otimes I_N)]) \\\\\n\\\\ p = [1,2,...p]\n\\end{gather}\\] \\(\\kappa_2\\) and \\(\\kappa_1\\) describe, respectively, the priors of the overall shrinkage level of the constant term and the variance-covariance matrix of the autoregressive slopes for the constant term. We specify \\(\\kappa_2=1\\) and \\(\\kappa_1=0.02\\) to respect Plagborg-Moller (2021) assumptions. We would not expect persistence in each lag for stationary variables following a random walk. Moreover, we set the prior of the autoregressive parameters \\(A\\) equal to a vector of zeros. The resulting full conditional posterior is: \\[\\begin{gather}\np(A,\\Sigma|Y,X) = p(A|Y,X,\\Sigma)p(\\Sigma|Y,X) \\\\\n\\\\ p(A|Y,X,\\Sigma) = MN_{K \\times N}(\\bar{A}, \\Sigma, \\bar{V}) \\\\\n\\\\ p(\\Sigma | Y, X) = IW_N(\\bar{S},\\bar{\\nu})\n\\end{gather}\\]\nWe can derive the full conditional posterior: \\[\\begin{gather}\nP(A,\\Sigma|Y,X) \\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n\\\\ \\propto L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma) \\\\\n\\\\ det(\\Sigma)^{-\\frac{T}{2}} \\times exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})' X'X (A-\\hat{A})\\right] \\right\\} \\\\\n\\\\ \\times exp\\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(Y-X\\hat{A})'(Y-X\\hat{A}) \\right] \\right\\} \\\\\n\\\\ \\times det(\\Sigma)^{-\\frac{N+K+\\underline{\\nu}+1}{2}} \\\\\n\\\\ \\times exp\\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A}) \\right] \\right\\} \\\\\n\\\\ \\times exp \\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1} \\underline{S} \\right] \\right\\}\n\\end{gather}\\]\nAfter some calculations:\n\\[\\begin{gather}\\\\\np(A,\\Sigma|Y,X) \\propto \\\\\n\\\\ det{(\\Sigma)}^{-\\frac{T+N+K+ \\underline{\\nu}\n+1}{2}} \\times exp\\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1} \\left[ (A-\\bar{A})^{'} \\bar{V}^{-1} (A-\\bar{A})+\\underline{S} +Y^{'}Y + \\underline{A}^{'} \\underline{V}^{-1}\\underline{A} -\\bar{A}^{'} \\bar{V}^{-1}\\bar{A}\\right]\\right]\\right\\}\n\\end{gather}\\]\nwhere the full conditional posterior has the same natural-conjugate form of our prior:\n\\[\\begin{gather}\np(A,\\Sigma|Y,X) = p(A|Y,X,\\Sigma)p(\\Sigma|Y,X) \\\\\n\\\\ p(A|Y,X,\\Sigma) = MN_{K \\times N}(\\bar{A}, \\Sigma, \\bar{V}) \\\\\n\\\\ p(\\Sigma | Y, X) = IW_N(\\bar{S},\\bar{\\nu})\\end{gather}\\]\nwith posterior parameters:\n\\[\\begin{gather}\n\\bar{V} = (X^{'}X+ \\underline{V}^{-1})^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X^{'}Y+\\underline{V}^{-1} \\underline{A}) \\\\\n\\\\ \\bar{\\nu} = T + \\underline{\\nu} \\\\\n\\\\ \\bar{S} = \\underline{S} + Y^{'}Y +  \\underline{A}^{'}\\underline{V}^{-1}\\underline{A} - \\bar{A}^{'}\\bar{V}^{-1}\\bar{A}\n\\end{gather}\\]\nIn order to compute our posterior parameters in R, we first specify values for our priors, then calculate the posteriors and draw \\(A\\) and \\(\\Sigma\\) respectively from Matrix-Variate-normal and Inverse Wishart distributions. At this point, we can obtain our structural parameters through a Cholesky decomposition of our matrix \\(\\Sigma\\), namely with \\(\\Sigma^{-1}=(B_0B_0^{'})\\).\n\n\nBasic Model Function\n  # setup function for our analysis\n  basic.model <- function(bigy, p, S, start, end){\n  ############################################################\n  N       = ncol(bigy)\n  K       = 1+N*p\n  ############################################################\n  Y       = bigy[(p+1):nrow(bigy),]\n  X       = matrix(1,nrow(Y),1)\n  for (i in 1:p){\n    X     = cbind(X,bigy[(p+1):nrow(bigy)-i,])\n  }\n  \n  A.prior     = matrix(0,K,N)\n  A.prior[2:(N+1),] <- diag(c(0,rep(1,N-1))) #0 for the instrument (stationary variable)\n  #A.prior[2:(N+1),] <- diag(c(0,rep(1,N-1))) #0 for the instrument (stationary variable)\n  V.prior     = (diag(c(1,0.02*((1:p)^(-2))%x%rep(1,N)))) #1 is kappa.2, 0.02 is kappa.1\n  S.prior     = diag(N)\n  nu.prior    = N+1\n  \n  # normal-inverse Wishart posterior parameters\n  ############################################################\n  V.bar.inv   = t(X)%*%X + diag(1/diag(V.prior)) #X'X+diag(V^-1)\n  V.bar       = solve(V.bar.inv) #inv(X'X+diag(V^-1))\n  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior) #V.bar(X'X+diag((V.prior)^-1(A.prior)))\n  nu.bar      = nrow(Y) + nu.prior \n  S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  #S.prior+Y'Y+(A.prior)'*diag(diag((V.prior)^-1))*A.prior-A.bar'*(X'X+diag(V^-1))*A.bar\n  S.bar.inv   = solve(S.bar)\n  \n  # posterior draws\n  ############################################################\n  Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   = apply(Sigma.posterior,3,solve)\n  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) #3 dimensional, S repetitions of rnorm\n  B.posterior       = array(NA,c(N,N,S))\n  L                 = t(chol(V.bar))\n  for (s in 1:S){\n    cholSigma.s     = chol(Sigma.posterior[,,s])\n    B.posterior[,,s]= t(cholSigma.s)\n    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%cholSigma.s\n}\n  #return the parameters of interest\n  results = list(\"B\" = B.posterior, \"A\" = A.posterior )\n  return(results)\n  }"
  },
  {
    "objectID": "index.html#artificial-data",
    "href": "index.html#artificial-data",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Artificial Data",
    "text": "Artificial Data\nWe generate two random walks \\(y1\\) and \\(y2\\) with 1000 observations each simulated from a bivariate Gaussian random walk process. We plot the raw series and the first difference below:\n\n\nArtificial Data\n  set.seed(420)\n  y1 <- ts(cumsum(rnorm(1000, 0, sd=1)))\n  y2 <- ts(cumsum(rnorm(1000, 0, sd=1)))\n  y.art <- cbind(y1,y2)\n  plot(diff(y.art), 1:1000, type = \"l\", main = \"Artificial data first difference\", ylab=\"\", xlab=\"\")\n\n\n\n\n\nThen, we use our two functions from the basic and extended model to simulate the intercept term posterior. We show in the plot that for 10 thousand draws we get an intercept close to zero for the \\(A_{1,1}\\) and \\(A_{1,2}\\) values. In addition, we get an identity matrix for the \\(B_{1,1}\\) and \\(B_{2,2}\\) values. Hence, the function works as we want.\n\n\nArtificial Data Results\n  set.seed(420)\n  y.art <- cbind(ts(cumsum(rnorm(1000, 0, sd=1))),ts(cumsum(rnorm(1000, 0, sd=1))))\n  par(mfrow=c(1,2),mar=c(2,2,2,2))\n  plot(diff(y.art), 1:1000, type = \"l\", main = \"Artificial data first difference\", ylab=\"\", xlab=\"\")\n\n\n\n\n\nArtificial Data Results\n  basic.artificial <- basic.model(y.art, 1, 10000, c(), c())\n  extended.artificial <- extended.model(y.art, 1, 1000, 9000)\n  B.basic    <- basic.artificial$B\n  A.basic    <- basic.artificial$A\n  B.extended <- extended.artificial$B.convergence\n  A.extended <-extended.artificial$A.convergence\n  \n  par(mfrow=c(4,2),mar=c(2,2,3,2))\n  plot(1:10000, B.basic[1,1,], type = \"l\", main = expression(paste(\"basic \" , B[11])), lwd=0.3, ylab=\"\", xlab=\"\", col=\"royalblue\")\n  plot(1:10000, B.basic[2,2,], type = \"l\", main = expression(paste(\"basic \" , B[22])), lwd=0.3, ylab=\"\", xlab=\"\", col=\"royalblue\")\n  plot(1:10000, A.basic[1,1,], type = \"l\", main = expression(paste(\"basic \" , A[11])), lwd=0.4, ylab=\"\", xlab=\"\", col=\"tomato\")\n  plot(1:10000, A.basic[1,2,], type = \"l\", main = expression(paste(\"basic \" , A[12])), lwd=0.4, ylab=\"\", xlab=\"\", col=\"tomato\")\n  plot(1:10000, B.extended[1,1,], type = \"l\", main = expression(paste(\"extended \" , B[11])), lwd=0.3, ylab=\"\", xlab=\"\", col=\"royalblue3\")\n  plot(1:10000, B.extended[2,2,], type = \"l\", main = expression(paste(\"extended \" , B[22])), lwd=0.3, ylab=\"\", xlab=\"\", col=\"royalblue3\")\n  plot(1:10000, A.extended[1,1,], type = \"l\", main = expression(paste(\"extended \" , A[11])), lwd=0.4, ylab=\"\", xlab=\"\", col=\"tomato3\")\n  plot(1:10000, A.extended[1,2,], type = \"l\", main = expression(paste(\"extended \" , A[12])), lwd=0.4, ylab=\"\", xlab=\"\", col=\"tomato3\")\n\n\n\n\n\nMoreover, we also plot the histograms of the values \\(\\kappa_A\\) and \\(\\kappa_{\\Sigma}\\) outlining their mean value. We also add a vertical line to define the mean parameter for all draws. In our original function, we have set the \\(\\kappa_{Sigma}\\) initial value to 1 and the results from 20 thousand draws indicate that the posterior median is \\(\\backsim0.04\\). Similarly, we set the initial value of \\(\\kappa_A\\) to one and obtain a posterior distribution with a median \\(\\sim 14.9\\).\n\n\nKappas Histograms Artifical Data\n  par(mfrow=c(1,2),mar=c(2,2,2,2))\n  hist(extended.artificial$k.a.convergence, breaks=\"Freedman-Diaconis\", col='tomato3', main = expression(paste(\"Slope Hyperparameter \", kappa[A])), border=F, xlim=c(0,30))\n  abline(v = mean(extended.artificial$k.a.convergence), col='purple4', lwd = 2)\n  hist(extended.artificial$k.sigma.convergence, breaks=\"Freedman-Diaconis\", col='royalblue', main = expression(paste(\"Covariance Hyperparameter \", kappa[Sigma])), border=F, xlim=c(0,0.15))\n  abline(v = mean(extended.artificial$k.sigma.convergence), col='purple4', lwd = 3)\n\n\n\n\n\nWe plot the \\(\\kappa\\)s parameters for the extended model using the Miranda-Agrippino and Rey (2020) dataset. The authors present the results of their impulse response functions in percentage changes, so we assume they have log-transformed the data. Moreover, the authors state in the online appendix that the global factor and global risk aversion variables are computed using first-differenced log-priced series. To support our statement, a plot of first-differenced data provides percentage changes on the ordinate axes, similar to what we would expect from a plot of \\(log(y_{t})-log(y_{t-1})\\). Hence, we will compute our parameters of interest using first-differenced data except for our instrument variable with 20 thousand draws in our Gibbs Sampler. Our initial \\(\\kappa_A\\) value is \\(\\sim 0.92\\) and our initial \\(\\kappa_{\\Sigma}\\) value is equal to 1. We can observe that the data changes significantly for the hyperprior parameter for the slope, but the same cannot be said for the variance-covariance hyperprior. After some tuning of the Inverse-Gamma2 and Gamma distribution priors for the \\(/kappa_A\\) and the \\(/kappa_[Sigma]\\) we found the following optimal values: \\[ \\underline{S}_A=0.5\\\\\n   \\underline{\\nu}_A=3\\\\\n   \\underline{s}_{\\Sigma}=0.01\\\\\n   \\underline{a}_{\\Sigma}=1\\]\n\n\n\n\n\nKappas Histograms Extended Model\n  extended.results       <- extended.model(y, 4, 500, 20000)\n  par(mfrow=c(1,2),mar=c(2,2,2,2))\n  hist(extended.results$k.a.convergence, breaks=\"Freedman-Diaconis\", col='tomato3', main = expression(paste(\"Slope Hyperparameter \", kappa[A])), border=F, xlim=c(12,22.5))\n  abline(v = mean(extended.results$k.a.convergence), col='purple4', lwd = 2)\n  hist(extended.results$k.sigma.convergence, breaks=\"Freedman-Diaconis\", col='royalblue', main = expression(paste(\"Covariance Hyperparameter \", kappa[Sigma])), border=F)\n  abline(v = mean(extended.results$k.sigma.convergence), col='purple4', lwd = 3)"
  },
  {
    "objectID": "index.html#order-of-integration-of-the-variables",
    "href": "index.html#order-of-integration-of-the-variables",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Order of Integration of the Variables",
    "text": "Order of Integration of the Variables\nWe run an augmented Dickey Fuller (ADF) test to determine the order of integration of our variables. The test rejects the null hypothesis that the variables are unit-root except for our instrument variable as expected. In order to provide more insight into the order of integration we re-run an ADF test with the first difference of the variables.\n\n\nADF-tests\n  library(tseries)\n  adf <- as.data.frame(matrix(nrow=14,ncol=3,NA))\n  rownames(adf) <- colnames(y[1:14])\n  colnames(adf) <- c(\"Dickey-Fuller\",\"Lag-order\", \"p-value\")\n  \n  for (i in 1:ncol(y)){\n    adf_tmp                 <-  adf.test(y[,i])\n    adf[i,\"Dickey-Fuller\"]  <-  round(as.numeric(adf_tmp[1]),3)\n    adf[i,\"Lag-order\"]      <-  as.numeric(adf_tmp[2])\n    adf[i,\"p-value\"]        <-  round(as.numeric(adf_tmp[4]),3)\n  }\n  \n  adf.diff <- as.data.frame(matrix(nrow=14,ncol=3,NA))\n  rownames(adf.diff) <- colnames(y[1:14])\n  colnames(adf.diff) <- c(\"Dickey-Fuller diff\",\"Lag-order diff\", \"p-value diff\")\n  \n  for (i in 1: ncol(y)){\n    tmp.diff                         <-  adf.test(diff(y[,i]))\n    adf.diff[i,\"Dickey-Fuller diff\"] <-  round(as.numeric(tmp.diff[1]),3)\n    adf.diff[i,\"Lag-order diff\"]     <-  as.numeric(tmp.diff[2])\n    adf.diff[i,\"p-value diff\"]       <-  round(as.numeric(tmp.diff[4]),3)\n  }\n  tab = cbind(t(y.names),adf, adf.diff)\n  colnames(tab)[1] <- \"Variable Names\"\n  knitr::kable(tab, index=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Names\nDickey-Fuller\nLag-order\np-value\nDickey-Fuller diff\nLag-order diff\np-value diff\n\n\n\n\nFF4 Instrument\n-4.492\n6\n0.010\n-10.666\n6\n0.01\n\n\n1Y Treasury Rate\n-2.612\n6\n0.318\n-4.047\n6\n0.01\n\n\nPCE\n-2.349\n6\n0.429\n-6.200\n6\n0.01\n\n\nIndustrial Production\n-1.692\n6\n0.706\n-4.354\n6\n0.01\n\n\nGlobal Real Production ex US\n-3.305\n6\n0.071\n-5.053\n6\n0.01\n\n\nGlobal Inflows All Sectors\n-2.032\n6\n0.562\n-4.474\n6\n0.01\n\n\nBIS EER\n-1.425\n6\n0.818\n-7.129\n6\n0.01\n\n\nGlobal Factor\n-2.031\n6\n0.563\n-7.166\n6\n0.01\n\n\nGlobal Risk Aversion\n-1.857\n6\n0.636\n-6.564\n6\n0.01\n\n\nGlobal Credit ex US\n-1.520\n6\n0.778\n-5.558\n6\n0.01\n\n\nLeverage US Brokers & Dealers\n-2.699\n6\n0.282\n-5.411\n6\n0.01\n\n\nLeverage EU Global Banks\n-3.276\n6\n0.076\n-5.696\n6\n0.01\n\n\nLeverage US Banks\n-1.529\n6\n0.774\n-5.348\n6\n0.01\n\n\nLeverage EU Banks\n-1.637\n6\n0.729\n-6.037\n6\n0.01"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "",
    "text": "::: justify > Abstract. > > Keywords. proxy svars, impulse responses, U.S. mps"
  },
  {
    "objectID": "index.html#gibbs-sampler",
    "href": "index.html#gibbs-sampler",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\nIn order to reach our analytical solutions we use a Monte Carlo Markov Chain (MCMC) method, namely the Gibbs Sampler procedure. We generate random draws from the joint posterior distribution and we update them at each iteration to compute our posterior distribution parameters. In our case we exploit the following procedure: Initialize \\(\\kappa_a\\) and \\(\\kappa_{\\Sigma}\\) at \\(\\kappa_a^{(0)}\\) and \\(\\kappa^{(0)}_{\\Sigma}\\)\nAt each iteration s:\n\nDraw $ (A,)^{(s)} p(A,| X,Y,*a^{(s-1)},* ^{(s-1)}) $\nDraw \\(\\kappa_a^{(s)} \\sim p(\\kappa_a|Y,X,A,\\Sigma)\\)\nDraw \\(\\kappa_{\\Sigma}^{(s)} \\sim p(\\kappa_{\\Sigma}|Y,X,A,\\Sigma)\\)\n\nRepeat steps 1 and 2 for \\((S_1 + S_2)\\) times. Discard the first \\(S_1\\) repetitions. Return the output as \\(\\left \\{ A^{(s)}, \\Sigma^{(s)} \\right \\}^{S2}_{s=S1+1}\\). In order to reach our analytical solutions we use a Monte Carlo Markov Chain (MCMC) method, namely the Gibbs Sampler procedure. We generate random draws from the joint posterior distribution and update them at each iteration to compute our posterior distribution parameters. In our case we exploit the following procedure: Initialize \\(\\kappa_A\\) and \\(\\kappa_{\\Sigma}\\) at \\(\\kappa_A^{(0)}\\) and \\(\\kappa^{(0)}_{\\Sigma}\\)\nAt each iteration s:\n\nDraw \\((A,\\Sigma)^{(s)} \\sim p(A,\\Sigma\\| X,Y,\\kappa*a^{(s-1)},* \\kappa{\\Sigma}^{(s-1)})\\)\nDraw \\(\\kappa_A^{(s)} \\sim p(\\kappa_A|Y,X,A,\\Sigma)\\)\nDraw \\(\\kappa_{\\Sigma}^{(s)} \\sim p(\\kappa_{\\Sigma}|Y,X,A,\\Sigma)\\)\n\nRepeat steps 1 and 2 for \\((S_1 + S_2)\\) times. Discard the first \\(S_1\\) repetitions. Return the output as \\(\\left \\{ A^{(s)}, \\Sigma^{(s)} \\right \\}^{S2}_{s=S1+1}\\).\n\n\nExtended Model Function 2\nextended.model <- function(bigy, p, S1, S2){\n  ############################################################\n  Y       = bigy[(p+1):nrow(bigy),]\n  X       = matrix(1,nrow(Y),1)\n  for (i in 1:p){\n    X     = cbind(X,bigy[(p+1):nrow(bigy)-i,])\n  }\n  \n  N       = ncol(bigy)\n  K       = 1+N*p\n  S=S1+S2 #sum of replications\n  # set the priors\n  A.prior     = matrix(0,K,N) #try to put is as 0\n  #A.prior[2:(N+1),] <- diag(c(0,rep(1,N-1)))\n  V.prior         = (diag(c(1,0.02*((1:p)^(-2))%x%rep(1,N)))) #1 is kappa.2, 0.02 is kappa.1\n  nu.prior        = N+1\n  #kappa.a priors\n  nu.prior.a      = 3    #ig2\n  s.a.prior       = 0.5\n  #kappa.sigma priors\n  a.sigma.prior   = 1  #rgamma\n  s.sigma.prior   = 0.01\n  \n  A.posterior         = array(rnorm(prod(c(K,N,S))), c(K, N, S))\n  B.posterior         = array(NA,c(N,N,S))\n  Sigma.post          = array(NA,c(N,N,S))\n  \n  k.sigma             = matrix(NA, S, 1)\n  k.a                 = matrix(NA, S, 1)\n  k.sigma[1] <- 1\n  k.a[1]     <- 1\n  \n  nu.bar      = nrow(Y) + nu.prior\n  nu.bar.a    = nu.prior.a + N*K\n  a.sigma.bar = (N*nu.prior)/2+a.sigma.prior\n  \n  for (s in 1:S) {\n    # normal-inverse Wishart, IG2, and Gamma posterior parameters\n    ############################################################\n    V.bar.inv   = t(X)%*%X + (k.a[s]^-1)*diag(1/diag(V.prior))\n    V.bar       = solve(V.bar.inv)\n    A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(k.a[s]*V.prior))%*%A.prior)\n    S.bar       = k.sigma[s]*diag(N) + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(k.a[s]*V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv   = solve(S.bar)\n    # posterior draws\n    ############################################################\n    Sigma.posterior.inv = rWishart(1, df=nu.bar, Sigma=S.bar.inv)\n    Sigma.posterior     = solve(Sigma.posterior.inv[,,1])\n    # Sigma.posterior     = matrix(Sigma.posterior, N, N)\n    L                   = t(chol(V.bar))\n    cholSigma.s         = chol(Sigma.posterior)\n    A.posterior[,,s]    = A.bar + L%*%A.posterior[,,s]%*%cholSigma.s\n    s.a.bar       <- s.a.prior + sum(diag(Sigma.posterior.inv[,,1] %*% t(A.posterior[,,s]-A.prior)%*% diag(1/diag(V.prior)) %*% (A.posterior[,,s]-A.prior)))\n    s.sigma.bar   <- (2*(sum(diag(Sigma.posterior.inv[,,1]))^-1)+((s.sigma.prior)^-1))^-1\n    if (s <= S){\n      #draw k.a from IG2\n      k.a[s+1]      <- s.a.bar / rchisq(1, df=nu.bar.a)\n      #draw k.sigma from gamma distribution\n      k.sigma[s+1]  <- rgamma(1, shape = a.sigma.bar, scale = s.sigma.bar)\n    }\n    \n    B.posterior[,,s]  = t(chol(Sigma.posterior))\n    Sigma.post[,,s]   = Sigma.posterior\n  }\n  #return the parameters of interest\n  results = list(\"B\" = B.posterior[,,S1+1:S2], \n                 \"A\" = A.posterior[,,S1+1:S2], \n                 \"Sigma\" = Sigma.post[,,S1+1:S2], \n                 \"k.a\" = k.a[S1+1:S2], \n                 \"k.sigma\" = k.sigma[S1+1:S2], \n                 \"B.convergence\" = B.posterior[,,1:S], \n                 \"A.convergence\" = A.posterior[,,1:S], \n                 \"Sigma.convergence\" = Sigma.post[,,1:S], \n                 \"k.a.convergence\" = k.a[1:S], \n                 \"k.sigma.convergence\" = k.sigma[1:S])\n  return(results)\n}"
  },
  {
    "objectID": "index.html#data-description",
    "href": "index.html#data-description",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Data Description",
    "text": "Data Description\nAgainst this framework, our interest is to study the degree by which U.S. monetary policy shocks can propagate throughout the world’s economies. In order to have a global picture we study macroeconomic variables that can affect and influence a FED change in the interest rate. The global variables are constructed by scrutinizing these countries: Argentina, Australia, Austria, Belarus, Belgium, Bolivia, Brazil, Bulgaria, Canada, Chile, Colombia, Costa Rica, Croatia, Cyprus, Czech Republic, Denmark, Ecuador, Finland, France, Germany, Greece, Hong Kong, Hungary, Iceland, Indonesia, Ireland, Italy, Japan, Latvia, Lithuania, Luxembourg, Malaysia, Malta, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Romania, Russia, Serbia, Singapore, Slovakia, Slovenia, South Africa, South Korea, Spain, Sweden, Switzerland, Thailand, Turkey, U.K., and the U.S.\nAs discussed in the previous section, we are ìncluding the variables of the global VAR of Miranda-Agrippino and Rey (2020). In the first graph, we include the following variables:\n-the U.S. industrial production index that measures the real output of all relevant establishments located in the U.S.; -the Bank for International Settlement (BIS) effective exchange rate (EER) for the United States, i.e. a summary measure calculated by the BIS to account for changes in the U.S. bilateral exchange rate against other countries by their trade importance; -global inflows, defined as direct cross-border credit flows from the U.S. to the aforementioned countries’ banks and non-bank recipients. This variable is key to explaining the degree of financial dependency of the rest of the world vis-à-vis the financial hegemon; -global domestic credit, another key variable in our VAR that outlines the total amount of funds in the world economy, including loans, debt instruments, and other forms of credit provided by financial institutions.\nIn the second graph, we outline four types of leverage. First of all, leverage can be defined as the ratio between assets and equity, with equity being the difference between assets and debts. In finance, this measurement refers to the use of borrowed funds to finance assets or investments. Against this backdrop, the authors construct this variable as the ratio between claims in the private sector, i.e. credit extended by banks and other financial institutions to the private sector, and the sum of transferable deposits held by depository corporations, excluding central banks. This ratio reflects the proportion of credit extended to the private sector relative to deposits held by depository corporations, excluding central banks. A higher ratio suggests a higher banking leverage level. The authors differentiate between different leverages given financial agents’ risk-taking behavior. As a matter of fact, we can observe that the leverage between EU global banks and US brokers and dealers is much larger than the leverage of big but not systemic EU and US banks. EU global banks include systematically important banks such as UBS and Unicredit. Global banks’ leverage is high for several reasons such as size and risk appetite. Brokers and dealers’ behavior can be explained by their risk-loving approach.\nIn the third graph, we include the FED policy rate coupled with the global real economic activity index (excluding the US). We can observe the lag effect of an increase in interest rates with a decrease in international economic activity. In the fourth graph we include the global factor discussed in the previous section, plotted with global risk aversion (one variable is the inverse of the other). The factor is rotated to provide an intuitive view that an increase in the factor (risk aversion) reflects an increase in world asset prices. Lastly, we plot the U.S. PCE deflator to measure changes in goods and services prices over time.\nLastly, we will add the aforementioned instrument on top of the \\(y_t\\) variable. In the next section we will provide the reason for this procedure."
  },
  {
    "objectID": "index.html#impulse-response-functions",
    "href": "index.html#impulse-response-functions",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Impulse Response Functions",
    "text": "Impulse Response Functions\nThe impulse response functions are the dynamic causal effects of the underlying shocks \\(u_t\\) on the economic measurements \\(y_t\\). Our model features the instrument in the first position. We will compute impulse response functions (IRFs) assuming that the instrument affects all the other variables exogenously. We define an IRF as a shock of the first variable in \\(u_t\\) (the instrument) on the 14 variables \\(n\\) of our model in \\(Y_t\\) at time \\(t\\) until time \\(t+i\\). In our case \\(i=24\\) because we want to study the IRFs for two years as the original paper authors do. Compactly, we can describe the computations as follows: \\[\\begin{gather}\n\\frac{\\partial y_{n.t+1}}{\\partial u_{1.t}}=\\theta_{nj.i}\n\\end{gather}\\] Plagborg-Moller (2021) assumption regarding the invertibility of \\(\\varepsilon\\) is satisfied given our Cholesky decomposition: \\[\\begin{bmatrix}\nb_0^{1,1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{2,1} & b_0^{2,2} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{3,1} & b_0^{3,2} & b_0^{3,3} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{4,1} & b_0^{4,2} & b_0^{4,3} & b_0^{4,4} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{5,1} & b_0^{5,2} & b_0^{5,3} & b_0^{5,4} & b_0^{5,5} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{6,1} & b_0^{6,2} & b_0^{6,3} & b_0^{6,4} & b_0^{6,5} & b_0^{6,6} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{7,1} & b_0^{7,2} & b_0^{7,3} & b_0^{7,4} & b_0^{7,5} & b_0^{7,6} & b_0^{7,7} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{8,1} & b_0^{8,2} & b_0^{8,3} & b_0^{8,4} & b_0^{8,5} & b_0^{8,6} & b_0^{8,7} & b_0^{8,8} & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{9,1} & b_0^{9,2} & b_0^{9,3} & b_0^{9,4} & b_0^{9,5} & b_0^{9,6} & b_0^{9,7} & b_0^{9,8} & b_0^{9,9} & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{10,1} & b_0^{10,2} & b_0^{10,3} & b_0^{10,4} & b_0^{10,5} & b_0^{10,6} & b_0^{10,7} & b_0^{10,8} & b_0^{10,9} & b_0^{10,10} & 0 & 0 & 0 & 0 \\\\\nb_0^{11,1} & b_0^{11,2} & b_0^{11,3} & b_0^{11,4} & b_0^{11,5} & b_0^{11,6} & b_0^{11,7} & b_0^{11,8} & b_0^{11,9} & b_0^{11,10} & b_0^{11,11} & 0 & 0 & 0 \\\\\nb_0^{12,1} & b_0^{12,2} & b_0^{12,3} & b_0^{12,4} & b_0^{12,5} & b_0^{12,6} & b_0^{12,7} & b_0^{12,8} & b_0^{12,9} & b_0^{12,10} & b_0^{12,11} & b_0^{12,12} & 0 & 0 \\\\\nb_0^{13,1} & b_0^{13,2} & b_0^{13,3} & b_0^{13,4} & b_0^{13,5} & b_0^{13,6} & b_0^{13,7} & b_0^{13,8} & b_0^{13,9} & b_0^{13,10} & b_0^{13,11} & b_0^{13,12} & b_0^{13,13} & 0 \\\\\nb_0^{14,1} & b_0^{14,2} & b_0^{14,3} & b_0^{14,4} & b_0^{14,5} & b_0^{14,6} & b_0^{14,7} & b_0^{14,8} & b_0^{14,9} & b_0^{14,10} & b_0^{14,11} & b_0^{14,12} & b_0^{14,13} & b_0^{14,14} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\text{Instrument} \\\\\n\\text{1Y Treasury Rate} \\\\\n\\text{PCE Deflator} \\\\\n\\text{Ind. Prod.} \\\\\n\\text{G. Prod. ex US} \\\\\n\\text{G. Inflows} \\\\\n\\text{BIS EER} \\\\\n\\text{G. Factor} \\\\\n\\text{G. Risk Aversion} \\\\\n\\text{G. Cred. ex US} \\\\\n\\text{Lev. US B&D} \\\\\n\\text{Lev. EU G. Banks} \\\\\n\\text{Lev. US Banks} \\\\\n\\text{Lev. EU Banks} \\\\\n\\end{bmatrix}\\] ### IRFs Basic Model We will outline IRFs for both our basic and extended models, computing 20 thousand draws for our estimates. Miranda-Agrippino and Rey (2020) normalize the IRFs so that the Treasury rate has a percentage point increase at horizon 0, but we do not include this normalization. Because of this, we cannot interpret the degree of shock as the authors do. From the 14 variables, we present only ten of them. We abstain from plotting the global factor because it is simply computed as the inverse of global risk aversion. In addition, we do not plot US brokers & dealers’ leverage and US banks’ leverage. This is because our main interests lies in spillovers of monetary policy outside the US. The abscissa scale is in months, given that we use monthly variables, and display the 68% and 90% density intervals. Out of the ten IRF plots, half coincide with the authors’ results. We will briefly outline the results. -Upon realisation, the one-year Treasury rate spikes in the first quarter, decreases in the third quarter and then hovers around zero in the remaining lags; -we would expect the PCE deflator to shrink, but it provides insignificant results in the first two quarters and increases thereafter; -industrial production shrinks in the first three quarters, and then mean-reverts but in insignificant bands; -global real production excluding the financial hegemon provides insignificant results in the first two lags and then increases, similarly to global inflows; -the BIS real effective exchange rate increases upon realisation as expected following the monetary policy shock, decreasing from the second quarter onwards; -global risk aversion - the proxy for global risky asset prices - spikes and hoovers around zero from the third quarter; -global credit excluding the US decreases as expected in the first two quarters and then increases thereafter; -the leverage drop immediately, but contrary to the original paper it does not mean-revert in the first quarter, and EU banks’ leverage provides insignificant results;\n\n\nIRFs Basic Model\n  # Impulse response functions basic model\n  # Forecast Error Variance Decomposition\n  ###########################################################\n  basic.results       <- basic.model(y, 12, 20000, c(1990,2), c(2010,12))\n  N=ncol(y)\n  h=24\n  p=12\n  S=20000 #S2 draws of the extended model\n  IRF.posterior     = array(NA,c(N,N,h+1,S))\n  IRF.inf.posterior = array(NA,c(N,N,S))\n  FEVD.posterior    = array(NA,c(N,N,h+1,S))\n  J                 = cbind(diag(N),matrix(0,N,N*(p-1))) #[I_N,0_{NxN(p-1)}]\n  \n  for (s in 1:S){\n  A.bold          = rbind(t(basic.results$A[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))  #rbind([A1...AP], cbind(I_{N(p-1)}, 0_{N(p-1)xN}))\n  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) #J*(I-A)^-1*J'\n  A.bold.power    = A.bold\n  for (i in 1:(h+1)){\n    if (i==1){\n      IRF.posterior[,,i,s]        = basic.results$B[,,s] #first value is first IRF\n    } else {\n      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*%basic.results$B[,,s] #J*A*J'*B.posterior\n      A.bold.power                = A.bold.power %*% A.bold\n    }\n    for (n in 1:N){\n    for (nn in 1:N){\n    FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)\n     }\n    }\n    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]\n  }\n}\n  FEVD.posterior    = 100*FEVD.posterior\n\n  #colours for IRFs\n  ############################################################\n  mcxs2  = \"#379683\"\n  mcxs3  = \"#5CDB95\"\n  mcxs4  = \"#8EE4AF\"\n  mcxs3.rgb   = col2rgb(mcxs3)\n  mcxs3.shade1= rgb(mcxs3.rgb[1],mcxs3.rgb[2],mcxs3.rgb[3], alpha=120, maxColorValue=255)\n  mcxs4.rgb   = col2rgb(mcxs4)\n  mcxs4.shade1= rgb(mcxs4.rgb[1],mcxs4.rgb[2],mcxs4.rgb[3], alpha=120, maxColorValue=255)\n\n\n  # plot IRFs basic model\n  ############################################################\n  #load(\"irf-instrument-fevd.RData\")\n  IRF.posterior.inst = IRF.posterior[,1,,] #takes the instruments IRFs\n  IRFs.k1           = apply(IRF.posterior.inst,1:2,mean) #mean of the S IRFs\n  IRFs.inf.k1       = apply(IRF.posterior.inst,1,mean)\n  rownames(IRFs.k1) = y.names\n\n  IRFs.k1.hdi    = apply(IRF.posterior.inst,1:2,hdi, credMass=0.68)\n  IRFs.k1.hdi2    = apply(IRF.posterior.inst,1:2,hdi, credMass=0.9)\n  hh          = 1:(h+1)\n  #pdf(file=\"FF-irf-mps1.pdf\", height=9, width=12)\n  par(mfrow=c(5,2), mar=c(2, 2, 2, 1.5),cex.axis=0.8, cex.lab=0.8, cex.main=0.9)\n  IRFs.wanted      <- c(2,3,4,5,6,7,9,10,12,14)\n  for (n in 1:14){\n    if (n %in% IRFs.wanted) {\n  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])\n  plot(hh,IRFs.k1[n,hh], type=\"l\", ylim=ylims, axes=FALSE, xlab=\"\", ylab=\"\", main =rownames(IRFs.k1)[n])\n  lines(hh, IRFs.k1[n,hh], lwd=2, col=mcxs2)\n  axis(1,c(4,8,12,16,20,24),c(\"4\",\"8\",\"12\",\"16\",\"20\",\"24\"))\n  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs3.shade1,border=mcxs3.shade1)\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi2[1,n,hh],IRFs.k1.hdi2[2,n,(h+1):1]), col=mcxs4.shade1,border=mcxs4.shade1)\n  abline(h=0)\n    }\n  }\n\n\n\n\n\n\nFEVD Basic Model\nMoreover, we include forecast error variance decomposition (FEVD) of two variables, i.e. EU Global banks’ leverage, and EU big but systemic banks leverage. FEVD provide the information of how much each variable contributes to the information of the other variables’ forecast variability at each horizon. We can observe that the FEVD for Global banks the other variables account significantly for the aforementioned information at further horizons. As a matter of fact, the information provided by the variable of interest contributes for only 13% at the last horizon. The larger contributors at the last horizon are the leverage of US and EU global but not systematically important banks (>40%).\n\n\nFEVD Basic Model for EU Global banks’ leverage\n  # colours for FEVDs\n  ############################################################\n  colours = c(\"deepskyblue1\",\"deepskyblue2\",\"deepskyblue\",\"deepskyblue3\",\"deepskyblue4\",\"dodgerblue\",\n           \"dodgerblue1\",\"dodgerblue2\",\"maroon1\",\"maroon\",\"maroon2\",\"magenta\",\"maroon3\",\"maroon4\")\n\n  # plot FEVDs for EU Global Banks' leverage\n  ############################################################\n  fevd.eubdlev  = apply(FEVD.posterior[12,,,],1:2,mean)\n  fevd.eubdlev  = rbind(rep(0,h+1),apply(fevd.eubdlev,2,cumsum))\n\n  par(mfrow=c(1,1), mar=rep(4,4),cex.axis=1, cex.lab=0.8)\n  plot(hh,fevd.eubdlev[1,], type=\"n\", ylim=c(0,100), axes=FALSE, xlab=\"\", ylab=\"\", main = \"FEVD EU Global Banks leverage Basic Model\")\n  axis(1,hh,c(\"\",\"\",\"\",\"4\",\"\",\"\",\"\",\"8\",\"\",\"\",\"\",\"12\",\"\",\"\",\"\",\"16\",\"\",\"\",\"\",\"20\",\"\",\"\",\"\",\"24\",\"\"),cex.axis=0.8)\n  axis(2,c(0,50,100),c(\"\",\"EUBDLEV\",\"\"), cex.axis=0.9)\n  for (n in 1:N){\n   polygon(c(hh,(h+1):1), c(fevd.eubdlev[n,hh],fevd.eubdlev[n+1,(h+1):1]), col=colours[n],border=colours[n])\n  }  \n  axis(4,(0.5*(fevd.eubdlev[1:14,25]+fevd.eubdlev[2:15,25]))[c(2,14)], c(\"Treasury rate\",\"EUBANKSL\"),cex.axis=0.6)\n\n\n\n\n\nIn addition, similar conclusions can be drawn to the FEVD of EU big but systematic banks’ leverage. The information provided by the variable of interest contributes for 12% at the last horizon. Other larger contributors at the last horizon are Leverage for EU global banks and US banks.\n\n\nFEVD Basic Model for EU banks’ leverage\n  # plot FEVDs for EU banks' leverage\n  ############################################################\n  fevd.eulev  = apply(FEVD.posterior[14,,,],1:2,mean) #real gdp\n  fevd.eulev  = rbind(rep(0,h+1),apply(fevd.eulev,2,cumsum))\n\n  #pdf(file=\"fevd-inst.pdf\", height=7, width=12)\n  par(mar=rep(4,4),cex.axis=1, cex.lab=0.8)\n  plot(hh,fevd.eulev[1,], type=\"n\", ylim=c(0,100), axes=FALSE, xlab=\"\", ylab=\"\",main=\"FEVD EU Banks leverage Basic Model\")\n  axis(1,hh,c(\"\",\"\",\"\",\"4\",\"\",\"\",\"\",\"8\",\"\",\"\",\"\",\"12\",\"\",\"\",\"\",\"16\",\"\",\"\",\"\",\"20\",\"\",\"\",\"\",\"24\",\"\"),cex.axis=0.8)\n  axis(2,c(0,50,100),c(\"\",\"EUBANKSL\",\"\"),cex.axis=0.9)\n  for (n in 1:N){\n   polygon(c(hh,(h+1):1), c(fevd.eulev[n,hh],fevd.eulev[n+1,(h+1):1]), col=colours[n],border=colours[n])\n  }\n  axis(4,(0.5*(fevd.eulev[1:14,25]+fevd.eulev[2:15,25]))[c(2,13)], c(\"Treasury rate\",\"Leverage US Banks\"),cex.axis=0.6)\n\n\n\n\n\n\n\nIRFs Extended Model\nRegarding the extended model, the IRFs are not in line with previous results or expectations. This is except for EU global banks’ leverage and the BIS effective exchange rate. We have worked on tuning different parameters for the \\(\\kappa_A\\) and \\(\\kappa_{\\Sigma}\\) hyperpriors, but unfortunately we still have to identify the drivers of these results. The IRFs of these variables provide insightful results only in the first 4-8 lags, but at further points the outcome is insignificant. One solution could be to implement a grid-search of different parameters for the hyperpriors prior parameters in the Gamma and Inverse-Gamma2 distributions, but time and computation power constraints prevent us from performing such exercise.\n\n\nIRFs Extended Model\n  # Extended model Impulse response functions\n  # Forecast Error Variance Decomposition\n  ###########################################################\n  p=4\n  IRF.posterior2     = array(NA,c(N,N,h+1,S))\n  IRF.inf.posterior2 = array(NA,c(N,N,S))\n  FEVD.posterior2    = array(NA,c(N,N,h+1,S))\n  J2                 = cbind(diag(N),matrix(0,N,N*(p-1))) #[I_N,0_{NxN(p-1)}]\n  \n  for (s in 1:S){\n  A.bold2          = rbind(t(extended.results$A[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))  #rbind([A1...AP], cbind(I_{N(p-1)}, 0_{N(p-1)xN}))\n  IRF.inf.posterior2[,,s]          = J2 %*% solve(diag(N*p)-A.bold2) %*% t(J2) #J*(I-A)^-1*J'\n  A.bold.power2    = A.bold2\n  for (i in 1:(h+1)){\n    if (i==1){\n      IRF.posterior2[,,i,s]        = extended.results$B[,,s] #first value is first IRF\n    } else {\n      IRF.posterior2[,,i,s]        = J2 %*% A.bold.power2 %*% t(J2) %*%extended.results$B[,,s] #J*A*J'*B.posterior\n      A.bold.power2                = A.bold.power2 %*% A.bold2\n    }\n    for (n in 1:N){\n    for (nn in 1:N){\n    FEVD.posterior2[n,nn,i,s]  = sum(IRF.posterior2[n,nn,1:i,s]^2)\n     }\n    }\n    FEVD.posterior2[,,i,s]         = diag(1/apply(FEVD.posterior2[,,i,s],1,sum))%*%FEVD.posterior2[,,i,s]\n  }\n}\n  FEVD.posterior2    = 100*FEVD.posterior2\n\n  #colours for IRFs\n  ############################################################\n  mcxs2  = \"#379683\"\n  mcxs3  = \"#5CDB95\"\n  mcxs4  = \"#8EE4AF\"\n  mcxs3.rgb   = col2rgb(mcxs3)\n  mcxs3.shade1= rgb(mcxs3.rgb[1],mcxs3.rgb[2],mcxs3.rgb[3], alpha=120, maxColorValue=255)\n  mcxs4.rgb   = col2rgb(mcxs4)\n  mcxs4.shade1= rgb(mcxs4.rgb[1],mcxs4.rgb[2],mcxs4.rgb[3], alpha=120, maxColorValue=255)\n\n\n  # plot IRFs extended model\n  ############################################################\n  IRF.posterior.inst2 = IRF.posterior2[,1,,] #takes the instruments IRFs\n  IRFs.k12           = apply(IRF.posterior.inst2,1:2,mean) #mean of the S IRFs\n  IRFs.inf.k12       = apply(IRF.posterior.inst2,1,mean)\n  rownames(IRFs.k12) = y.names\n\n  IRFs.k1.hdi3    = apply(IRF.posterior.inst2,1:2,hdi, credMass=0.68)\n  IRFs.k1.hdi4    = apply(IRF.posterior.inst2,1:2,hdi, credMass=0.9)\n  hh          = 1:(h+1)\n  par(mfrow=c(5,2), mar=c(2, 2, 2, 1.5),cex.axis=0.8, cex.lab=0.8, cex.main=0.9)\n  for (n in 1:14){\n    if (n %in% IRFs.wanted) {\n  ylims     = range(IRFs.k12[n,hh],IRFs.k1.hdi3[,n,hh])\n  plot(hh,IRFs.k12[n,hh], type=\"l\", ylim=ylims, axes=FALSE, xlab=\"\", ylab=\"\", main =rownames(IRFs.k12)[n])\n  lines(hh, IRFs.k12[n,hh], lwd=2, col=mcxs2)\n  axis(1,c(4,8,12,16,20,24),c(\"4\",\"8\",\"12\",\"16\",\"20\",\"24\"))\n  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi3[1,n,hh],IRFs.k1.hdi3[2,n,(h+1):1]), col=mcxs3.shade1,border=mcxs3.shade1)\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi4[1,n,hh],IRFs.k1.hdi4[2,n,(h+1):1]), col=mcxs4.shade1,border=mcxs4.shade1)\n  abline(h=0)\n    }\n  }\n\n\n\n\n\n\n\nFEVD Extended Model\nWe also plot the same FEVD of the same variables of the previous section. Differenyly from IRFs, the extended model FEVDs are almost identical to the ones of the basic model.\n\n\nFEVD Extended Model for EU Global banks’ leverage\n  # plot FEVDs for EU Global Banks' leverage\n  ############################################################\n  fevd.eubdlev2  = apply(FEVD.posterior2[12,,,],1:2,mean)\n  fevd.eubdlev2  = rbind(rep(0,h+1),apply(fevd.eubdlev2,2,cumsum))\n  par(mfrow=c(1,1), mar=c(4, 4, 4, 4),cex.axis=1, cex.lab=0.8)\n  plot(hh,fevd.eubdlev2[1,], type=\"n\", ylim=c(0,100), axes=FALSE, xlab=\"\", ylab=\"\", main = \"FEVD EU Global Banks leverage Extended Model\")\n   axis(1,hh,c(\"\",\"\",\"\",\"4\",\"\",\"\",\"\",\"8\",\"\",\"\",\"\",\"12\",\"\",\"\",\"\",\"16\",\"\",\"\",\"\",\"20\",\"\",\"\",\"\",\"24\",\"\"),cex.axis=0.8)\n  axis(2,c(0,50,100),c(\"\",\"EUBDLEV \",\"\"), cex.axis=0.9)\n  for (n in 1:N){\n   polygon(c(hh,(h+1):1), c(fevd.eubdlev2[n,hh],fevd.eubdlev2[n+1,(h+1):1]), col=colours[n],border=colours[n])\n  }  \n  axis(4,(0.5*(fevd.eubdlev2[1:14,25]+fevd.eubdlev2[2:15,25]))[c(2,14)], c(\"Treasury rate\",\"EUBANKSL\"),cex.axis=0.6)\n\n\n\n\n\n\n\nFEVD Extended Model for EU banks’ leverage\n  # plot FEVDs for EU banks' leverage\n  ############################################################\n  fevd.eulev2  = apply(FEVD.posterior2[14,,,],1:2,mean) #real gdp\n  fevd.eulev2  = rbind(rep(0,h+1),apply(fevd.eulev2,2,cumsum))\n\n  par(mar=rep(4,4),cex.axis=1, cex.lab=0.8)\n  plot(hh,fevd.eulev2[1,], type=\"n\", ylim=c(0,100), axes=FALSE, xlab=\"\", ylab=\"\",main=\"FEVD EU Banks leverage Extended Model\")\n  axis(1,hh,c(\"\",\"\",\"\",\"4\",\"\",\"\",\"\",\"8\",\"\",\"\",\"\",\"12\",\"\",\"\",\"\",\"16\",\"\",\"\",\"\",\"20\",\"\",\"\",\"\",\"24\",\"\"),cex.axis=0.8)\n  axis(2,c(0,50,100),c(\"\",\"EUBANKSL\",\"\"),cex.axis=0.9)\n  for (n in 1:N){\n   polygon(c(hh,(h+1):1), c(fevd.eulev2[n,hh],fevd.eulev2[n+1,(h+1):1]), col=colours[n],border=colours[n])\n  }  \n  axis(4,(0.5*(fevd.eulev2[1:14,25]+fevd.eulev2[2:15,25]))[c(2,13)], c(\"Treasury rate\",\"Leverage US Banks\"),cex.axis=0.6)"
  },
  {
    "objectID": "index.html#extended-model",
    "href": "index.html#extended-model",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "Extended Model",
    "text": "Extended Model\nIn the extended model, we set hyperprior parameters for the autoregressive parameter \\(\\kappa_A\\) to follow an Inverse Gamma 2 distribution \\(IG2(\\underline{S}_{\\kappa},\\underline{\\nu}_{\\kappa})\\) and \\(\\kappa_{\\Sigma}\\) hyperprior parameter for the variance-covariance matrix to follow a Gamma Distribution \\(G(\\underline{S}_{\\Sigma},\\underline{a}_{\\Sigma})\\). We define a hierarchical model to provide flexibility to our model and hopefully reduce uncertainty. We will define the full conditional posterior of the hyperparameter \\(\\kappa_A\\) first.\n\\[\\begin{gather}\np(\\kappa_A | A,\\Sigma, Y,X) \\propto L(Y|X,A,\\Sigma) \\times p(\\kappa_A) \\times p(A|\\Sigma,\\kappa_A) \\times p(\\Sigma|\\kappa_A) \\\\\n\\\\ \\propto p(\\kappa_A) \\times p(A|\\Sigma,\\kappa_A) \\\\\n\\\\ \\propto (\\kappa_A)^{-\\frac{\\underline{\\nu_a}+2}{2}}\nexp\\left\\{ -\\frac{1}{2} \\frac{\\underline{S_a}}{\\kappa_A} \\right\\}  \\times exp\\left\\{-\\frac{1}{2}tr\\left[\\Sigma^{-1}(A-\\underline{A_{\\kappa}})^{'} \\frac{1}{\\kappa}(\\underline{V_{\\kappa}})^{-1} (A-\\underline{A})\\right]\\right\\} \\times det(\\kappa_A \\underline{V})^{-\\frac{N}{2}} \\\\\n\\\\ \\propto (\\kappa_A)^{-\\frac{\\underline{\\nu_a}_{\\kappa_A}+2+NK}{2}} exp \\left\\{-\\frac{1}{2} \\frac{1}{\\kappa_A} \\left[\\underline{S_a}_{\\kappa_A} + tr \\left[\\Sigma^{-1}(A-\\underline{A})^{'}\\underline{V}^{-1}(A-\\underline{A}) \\right]\\right] \\right\\}\n\\end{gather}\\]\nwhere we recognise the kernel of an Inverse Gamma 2 Distribution with\n\\[\\begin{gather}\n\\bar{S}_a = \\underline{S}_a+tr \\left[ \\Sigma^{-1} (A-\\underline{A})^{'} \\underline{V}^{-1} (A-\\underline{A})\\right] \\\\\n\\\\ \\bar{\\nu}_a = \\underline{\\nu}_a+NK\n\\end{gather}\\]\nIn addition, we obtain a similar full conditional posterior of the hyperparameter \\(\\kappa_{\\Sigma}\\). \\[\\begin{gather}\np(\\kappa_{\\Sigma} | A,\\Sigma, Y,X) \\propto L(Y|X,A,\\Sigma) \\times p(\\kappa_{\\Sigma}) \\times p(A|\\Sigma,\\kappa_A) \\times p(\\Sigma|\\kappa_{\\Sigma}) \\times p(\\kappa_A) \\\\\n\\\\ \\propto p(\\kappa_{\\Sigma}) \\times p(\\Sigma|\\kappa_{\\Sigma}) \\\\\n\\\\ \\propto (\\kappa_{\\Sigma})^{-\\frac{\\underline{\\nu}N}{2}}\nexp\\left[{ -\\frac{1}{2} \\frac{\\kappa_{\\Sigma}}{tr\\left [\\Sigma^{-1}\\underline{s}_{\\Sigma} \\right ]^{-1}}} \\right\\}  \\times (\\kappa_{\\Sigma})^{\\underline{a}_{\\Sigma}-1}exp\\left [{-\\frac{\\kappa_{\\Sigma}}{\\underline{s}_{\\Sigma}}}  \\right ] \\\\\n\\\\ \\propto (\\kappa_{\\Sigma})^\\frac{{}{N\\underline{\\nu}+2\\underline{a}_{\\Sigma}-2}}{2}exp\\left [{-\\frac{\\kappa_{\\Sigma}}{\\left [2tr\\left[\\Sigma^{-1}\\underline{s}_{\\Sigma} \\right ]^{-1}+\\left[\\underline{s}_{\\Sigma} \\right ]^{-1}\\right ]^{-1}}}  \\right ] \\\\\n\\end{gather}\\] where we can recognise the kernel of an Gamma Distribution with \\[\\begin{gather}\n\\bar{S}_{\\Sigma} = {\\left [2\\left[tr\\Sigma^{-1}\\underline{s}_{\\Sigma} \\right ]^{-1}+\\left[\\underline{s}_{\\Sigma} \\right ]^{-1}\\right ]^{-1}} \\\\\n\\\\ \\bar{a}_{\\Sigma} = \\frac{N\\underline{\\nu}}{2}+\\underline{a}_{\\Sigma}\n\\end{gather}\\]\nTherefore, our new full conditional posterior distribution will be as following: The full conditional posterior of \\((A,\\Sigma)\\) is: \\[\\begin{gather}\np(A,\\Sigma|X,Y,\\kappa_a,\\kappa_{\\Sigma}) \\propto L(A,\\Sigma|Y,X) \\times p(A|\\Sigma,\\kappa_a) \\times p(\\Sigma|\\kappa_{\\Sigma}) \\\\\n\\\\ \\propto det(\\Sigma)^{-\\frac{K}{2}} exp \\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(Y-XA)^{'}(Y-XA)\\right] \\right\\} \\\\\n\\\\ \\times exp \\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\underline{A})^{'}(\\kappa_a \\underline{V})^{-1}(A-\\underline{A}) \\right] \\right\\} \\\\\n\\\\ \\times det(\\Sigma)^{\\frac{\\underline{\\nu}+N+1}{2}} exp\\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}\\kappa_{\\Sigma} \\right] \\right\\}\n\\end{gather}\\]\nWe recognize kernel of matrix-normal inverse Wishart distribution, with parameters as follows: \\[\\begin{gather}\n\\bar{V} = (X'X+(\\kappa_a \\underline{V}))^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X'Y+(\\kappa_a \\underline{V}^{-1}\\underline{A})) \\\\ \\\\ \\bar{S} = I_N\\kappa_{\\Sigma}+Y'Y+\\underline{A}^{'}(\\kappa_a \\underline{V})^{-1}\\underline{A} - \\bar{A}^{'} \\bar{V}^{-1}\\bar{A} \\\\\n\\end{gather}\\] where we can recognise the kernel of an Gamma Distribution with \\[\\begin{gather}\n\\bar{s}_{\\Sigma} = {\\left [2\\left[tr\\Sigma^{-1}\\underline{s}_{\\Sigma} \\right ]^{-1}+\\left[\\underline{s}_{\\Sigma} \\right ]^{-1}\\right ]^{-1}} \\\\\n\\\\ \\bar{a}_{\\Sigma} = \\frac{N\\underline{\\nu}}{2}+\\underline{a}_{\\Sigma}\n\\end{gather}\\]\nTherefore, our new full conditional posterior distribution will be as follows: \\[\\begin{gather}\np(A,\\Sigma|X,Y,\\kappa_A,\\kappa_{\\Sigma}) \\propto L(A,\\Sigma|Y,X) \\times p(A|\\Sigma,\\kappa_A) \\times p(\\Sigma|\\kappa_{\\Sigma}) \\\\\n\\\\ \\propto det(\\Sigma)^{-\\frac{K}{2}} exp \\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(Y-XA)^{'}(Y-XA)\\right] \\right\\} \\\\\n\\\\ \\times exp \\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\underline{A})^{'}(\\kappa_A \\underline{V})^{-1}(A-\\underline{A}) \\right] \\right\\} \\\\\n\\\\ \\times det(\\Sigma)^{\\frac{\\underline{\\nu}+N+1}{2}} exp\\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}\\kappa_{\\Sigma} \\right] \\right\\}\n\\end{gather}\\]\nWe recognize the kernel of a matrix-normal inverse Wishart distribution, with parameters as follows: \\[\\begin{gather}\n\\bar{V} = (X'X+(\\kappa_A \\underline{V}))^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X'Y+(\\kappa_A \\underline{V}^{-1}\\underline{A})) \\\\ \\\\ \\bar{S} = I_N\\kappa_{\\Sigma}+Y'Y+\\underline{A}^{'}(\\kappa_A \\underline{V})^{-1}\\underline{A} - \\bar{A}^{'} \\bar{V}^{-1}\\bar{A} \\\\\n\\\\ \\bar{\\nu} = T + \\underline{\\nu}\n\\end{gather}\\]"
  },
  {
    "objectID": "index copy.html",
    "href": "index copy.html",
    "title": "A Proxy-SVAR Reproduction Model",
    "section": "",
    "text": "{css, echo = FALSE} .justify { text-align: justify !important }\n\n\\[\n\\begin{bmatrix}\nb_0^{1,1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{2,1} & b_0^{2,2} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{3,1} & b_0^{3,2} & b_0^{3,3} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{4,1} & b_0^{4,2} & b_0^{4,3} & b_0^{4,4} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{5,1} & b_0^{5,2} & b_0^{5,3} & b_0^{5,4} & b_0^{5,5} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{6,1} & b_0^{6,2} & b_0^{6,3} & b_0^{6,4} & b_0^{6,5} & b_0^{6,6} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{7,1} & b_0^{7,2} & b_0^{7,3} & b_0^{7,4} & b_0^{7,5} & b_0^{7,6} & b_0^{7,7} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{8,1} & b_0^{8,2} & b_0^{8,3} & b_0^{8,4} & b_0^{8,5} & b_0^{8,6} & b_0^{8,7} & b_0^{8,8} & 0 & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{9,1} & b_0^{9,2} & b_0^{9,3} & b_0^{9,4} & b_0^{9,5} & b_0^{9,6} & b_0^{9,7} & b_0^{9,8} & b_0^{9,9} & 0 & 0 & 0 & 0 & 0 \\\\\nb_0^{10,1} & b_0^{10,2} & b_0^{10,3} & b_0^{10,4} & b_0^{10,5} & b_0^{10,6} & b_0^{10,7} & b_0^{10,8} & b_0^{10,9} & b_0^{10,10} & 0 & 0 & 0 & 0 \\\\\nb_0^{11,1} & b_0^{11,2} & b_0^{11,3} & b_0^{11,4} & b_0^{11,5} & b_0^{11,6} & b_0^{11,7} & b_0^{11,8} & b_0^{11,9} & b_0^{11,10} & b_0^{11,11} & 0 & 0 & 0 \\\\\nb_0^{12,1} & b_0^{12,2} & b_0^{12,3} & b_0^{12,4} & b_0^{12,5} & b_0^{12,6} & b_0^{12,7} & b_0^{12,8} & b_0^{12,9} & b_0^{12,10} & b_0^{12,11} & b_0^{12,12} & 0 & 0 \\\\\nb_0^{13,1} & b_0^{13,2} & b_0^{13,3} & b_0^{13,4} & b_0^{13,5} & b_0^{13,6} & b_0^{13,7} & b_0^{13,8} & b_0^{13,9} & b_0^{13,10} & b_0^{13,11} & b_0^{13,12} & b_0^{13,13} & 0 \\\\\nb_0^{14,1} & b_0^{14,2} & b_0^{14,3} & b_0^{14,4} & b_0^{14,5} & b_0^{14,6} & b_0^{14,7} & b_0^{14,8} & b_0^{14,9} & b_0^{14,10} & b_0^{14,11} & b_0^{14,12} & b_0^{14,13} & b_0^{14,14} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\text{Instrument} \\\\\n\\text{1Y Treasury Rate} \\\\\n\\text{PCE Deflator} \\\\\n\\text{Ind. Prod.} \\\\\n\\text{G. Prod. ex US} \\\\\n\\text{G. Inflows} \\\\\n\\text{BIS EER} \\\\\n\\text{G. Factor} \\\\\n\\text{G. Risk Aversion} \\\\\n\\text{G. Cred. ex US} \\\\\n\\text{Lev. US B&D} \\\\\n\\text{Lev. EU G. Banks} \\\\\n\\text{Lev. US Banks} \\\\\n\\text{Lev. EU Banks} \\\\\n\\end{bmatrix}\n\\]"
  }
]